{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Avaliação Blind Test: Modelo Padrão vs Agente com ISR\n",
    "\n",
    "## Sextant Banking Edition - Testes Cegos (Sem Vazamento de Informação)\n",
    "\n",
    "**Autor:** SK-Crossroads  \n",
    "**Data:** Janeiro 2026  \n",
    "**Versão:** 4.0 (Blind Test - Zero Data Leakage)\n",
    "\n",
    "---\n",
    "\n",
    "### Problema Identificado na Versão 3\n",
    "\n",
    "Na versão anterior, identificamos **vazamento de informação (data leakage)**:\n",
    "\n",
    "| Problema | Exemplo | Impacto |\n",
    "|----------|---------|---------|  \n",
    "| Cliente ID revelador | `TEMP_ALUCINACAO_001` | Modelo pode inferir que é fictício |\n",
    "| CPF padrão fictício | `999.999.999-99` | Padrão óbvio de teste |\n",
    "| Tipo explícito | `tipo: alucinacao` | Label leak direto |\n",
    "\n",
    "### Solução nesta versão (Blind Test)\n",
    "\n",
    "1. **Anonimização completa** - Cliente IDs são substituídos por UUIDs neutros\n",
    "2. **CPFs realistas** - CPFs fictícios são substituídos por CPFs válidos gerados\n",
    "3. **Sem labels** - Nenhuma informação sobre tipo ou decisão esperada vai ao modelo\n",
    "4. **Avaliação separada** - Ground truth é mantido apenas internamente\n",
    "\n",
    "### Objetivo\n",
    "\n",
    "Testar se o modelo consegue detectar clientes problemáticos baseado **APENAS nos dados financeiros**, não em pistas nos identificadores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup do Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Diretório do projeto: /home/dumoura/Kunumi/Hallucinations_ISR_V4\n",
      "\n",
      "[INFO] Versão: BLIND TEST (sem vazamento de informação)\n",
      "[INFO] Cliente IDs serão anonimizados antes de enviar ao modelo\n"
     ]
    }
   ],
   "source": [
    "# Imports necessários\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import uuid\n",
    "import random\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Encontra o diretório raiz do projeto\n",
    "def find_project_root():\n",
    "    \"\"\"Encontra o diretório raiz do projeto.\"\"\"\n",
    "    current = Path.cwd()\n",
    "    \n",
    "    if current.name == \"notebooks\":\n",
    "        candidate = current.parent\n",
    "        if (candidate / \"feature\").exists():\n",
    "            return candidate\n",
    "    \n",
    "    required_files = [\"feature/banco_politicas_diretrizes.md\", \"feature/clientes_teste_mock.json\"]\n",
    "    \n",
    "    for parent in [current] + list(current.parents):\n",
    "        if all((parent / f).exists() for f in required_files):\n",
    "            return parent\n",
    "    \n",
    "    fallback = Path(\"/home/dumoura/Kunumi/Hallucinations_ISR_V4\")\n",
    "    if fallback.exists():\n",
    "        return fallback\n",
    "    \n",
    "    raise FileNotFoundError(\"Não foi possível encontrar a raiz do projeto\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "load_dotenv(PROJECT_ROOT / \".env\")\n",
    "\n",
    "print(f\"[OK] Diretório do projeto: {PROJECT_ROOT}\")\n",
    "print(f\"\\n[INFO] Versão: BLIND TEST (sem vazamento de informação)\")\n",
    "print(f\"[INFO] Cliente IDs serão anonimizados antes de enviar ao modelo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Cliente OpenAI inicializado\n",
      "[OK] Modelo: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# Verifica API Key e inicializa cliente\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY não encontrada no .env!\")\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "\n",
    "print(f\"[OK] Cliente OpenAI inicializado\")\n",
    "print(f\"[OK] Modelo: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Funções de Anonimização (Anti-Leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Funções de anonimização definidas\n",
      "\n",
      "Exemplo de CPF gerado: 475.320.592-43\n",
      "Exemplo de ID anônimo: CLI_55F0BBA0\n"
     ]
    }
   ],
   "source": [
    "def gerar_cpf_valido():\n",
    "    \"\"\"\n",
    "    Gera um CPF válido (com dígitos verificadores corretos).\n",
    "    Usado para substituir CPFs obviamente fictícios.\n",
    "    \"\"\"\n",
    "    def calcular_digito(cpf_parcial):\n",
    "        soma = 0\n",
    "        peso = len(cpf_parcial) + 1\n",
    "        for digito in cpf_parcial:\n",
    "            soma += int(digito) * peso\n",
    "            peso -= 1\n",
    "        resto = soma % 11\n",
    "        return '0' if resto < 2 else str(11 - resto)\n",
    "    \n",
    "    # Gera 9 dígitos aleatórios (evitando padrões óbvios)\n",
    "    while True:\n",
    "        base = ''.join([str(random.randint(0, 9)) for _ in range(9)])\n",
    "        # Evita CPFs com todos dígitos iguais\n",
    "        if len(set(base)) > 1:\n",
    "            break\n",
    "    \n",
    "    # Calcula dígitos verificadores\n",
    "    digito1 = calcular_digito(base)\n",
    "    digito2 = calcular_digito(base + digito1)\n",
    "    \n",
    "    cpf = base + digito1 + digito2\n",
    "    return f\"{cpf[:3]}.{cpf[3:6]}.{cpf[6:9]}-{cpf[9:]}\"\n",
    "\n",
    "\n",
    "def gerar_cliente_id_anonimo(seed: str) -> str:\n",
    "    \"\"\"\n",
    "    Gera um cliente_id neutro baseado em hash.\n",
    "    Não revela nenhuma informação sobre o tipo do cliente.\n",
    "    \"\"\"\n",
    "    # Usa hash para gerar ID determinístico mas não revelador\n",
    "    hash_obj = hashlib.sha256(seed.encode())\n",
    "    hash_hex = hash_obj.hexdigest()[:8].upper()\n",
    "    return f\"CLI_{hash_hex}\"\n",
    "\n",
    "\n",
    "def anonimizar_cliente(cliente: Dict, indice: int) -> Dict:\n",
    "    \"\"\"\n",
    "    Anonimiza um cliente removendo todas as pistas identificadoras.\n",
    "    \n",
    "    O que é anonimizado:\n",
    "    - cliente_id: substituído por ID neutro\n",
    "    - cpf: se for obviamente fictício, gera um válido\n",
    "    - nome: mantido (nomes são neutros)\n",
    "    \n",
    "    O que NÃO é alterado (dados financeiros reais):\n",
    "    - score_atual\n",
    "    - renda_mensal\n",
    "    - defaults_historico\n",
    "    - endividamento_atual\n",
    "    - tempo_relacionamento\n",
    "    \"\"\"\n",
    "    cliente_anonimo = deepcopy(cliente)\n",
    "    \n",
    "    # 1. Anonimizar cliente_id\n",
    "    original_id = cliente.get(\"cliente_id\", f\"unknown_{indice}\")\n",
    "    seed = f\"{original_id}_{indice}_{random.randint(1000, 9999)}\"\n",
    "    cliente_anonimo[\"cliente_id\"] = gerar_cliente_id_anonimo(seed)\n",
    "    \n",
    "    # 2. Verificar e substituir CPF se for obviamente fictício\n",
    "    cpf = cliente.get(\"cpf\", \"\")\n",
    "    cpfs_ficticios = [\n",
    "        \"999.999.999-99\", \"000.000.000-00\", \"111.111.111-11\",\n",
    "        \"222.222.222-22\", \"333.333.333-33\", \"444.444.444-44\",\n",
    "        \"555.555.555-55\", \"666.666.666-66\", \"777.777.777-77\",\n",
    "        \"888.888.888-88\"\n",
    "    ]\n",
    "    \n",
    "    if cpf in cpfs_ficticios or \"999.999\" in cpf or \"000.000\" in cpf:\n",
    "        cliente_anonimo[\"cpf\"] = gerar_cpf_valido()\n",
    "    \n",
    "    # 3. Remover campos que possam dar pistas\n",
    "    campos_remover = [\"tipo\", \"tipo_cenario\", \"categoria\", \"label\", \"esperado\"]\n",
    "    for campo in campos_remover:\n",
    "        cliente_anonimo.pop(campo, None)\n",
    "    \n",
    "    return cliente_anonimo\n",
    "\n",
    "\n",
    "# Teste das funções\n",
    "print(\"[OK] Funções de anonimização definidas\")\n",
    "print(f\"\\nExemplo de CPF gerado: {gerar_cpf_valido()}\")\n",
    "print(f\"Exemplo de ID anônimo: {gerar_cliente_id_anonimo('teste_123')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Carregando Artefatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Políticas carregadas: 36047 caracteres\n"
     ]
    }
   ],
   "source": [
    "# Carrega políticas do banco\n",
    "politicas_path = PROJECT_ROOT / \"feature\" / \"banco_politicas_diretrizes.md\"\n",
    "\n",
    "with open(politicas_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    POLITICAS_BANCO = f.read()\n",
    "\n",
    "print(f\"[OK] Políticas carregadas: {len(POLITICAS_BANCO)} caracteres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Carregados 25 clientes de teste\n"
     ]
    }
   ],
   "source": [
    "# Carrega clientes de teste\n",
    "clientes_path = PROJECT_ROOT / \"feature\" / \"clientes_teste_mock.json\"\n",
    "\n",
    "with open(clientes_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    clientes_data = json.load(f)\n",
    "\n",
    "clientes_raw = clientes_data[\"clientes\"]\n",
    "print(f\"[OK] Carregados {len(clientes_raw)} clientes de teste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Preparando Dataset com Anonimização\n",
    "\n",
    "**IMPORTANTE:** O modelo receberá dados anonimizados. O ground truth é mantido apenas internamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Dataset blind criado com 25 casos\n",
      "\n",
      "Distribuição (ground truth interno):\n",
      "  - Alucinação: 2\n",
      "  - Bom cliente: 9\n",
      "  - Score baixo: 6\n",
      "  - Borderline: 5\n",
      "  - Múltiplos defaults: 3\n"
     ]
    }
   ],
   "source": [
    "def determinar_ground_truth(cliente: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Determina a decisão esperada (ground truth) baseado nos dados ORIGINAIS.\n",
    "    \n",
    "    Esta função usa os dados originais (antes da anonimização) para\n",
    "    determinar qual seria a decisão correta.\n",
    "    \"\"\"\n",
    "    cliente_id = cliente.get(\"cliente_id\", \"\")\n",
    "    score = cliente.get(\"score_atual\", 0)\n",
    "    cpf = cliente.get(\"cpf\", \"\")\n",
    "    defaults = cliente.get(\"defaults_historico\", []) or []\n",
    "    num_defaults = len(defaults)\n",
    "    \n",
    "    # Detectar cliente fictício pelos dados ORIGINAIS\n",
    "    eh_ficticio = (\n",
    "        \"TEMP_\" in cliente_id or\n",
    "        \"ALUCINACAO\" in cliente_id.upper() or\n",
    "        \"FAKE\" in cliente_id.upper() or\n",
    "        \"999.999\" in cpf or\n",
    "        \"000.000\" in cpf\n",
    "    )\n",
    "    \n",
    "    # Detectar dados inconsistentes (sinais de alucinação)\n",
    "    dados_inconsistentes = False\n",
    "    \n",
    "    # Score muito alto mas com defaults recentes\n",
    "    if score >= 800 and num_defaults > 0:\n",
    "        defaults_recentes = [d for d in defaults if \"2024\" in str(d.get(\"data\", \"\")) or \"2025\" in str(d.get(\"data\", \"\"))]\n",
    "        if defaults_recentes:\n",
    "            dados_inconsistentes = True\n",
    "    \n",
    "    # Renda muito alta mas score baixo\n",
    "    renda = cliente.get(\"renda_mensal\", 0)\n",
    "    if renda > 50000 and score < 500:\n",
    "        dados_inconsistentes = True\n",
    "    \n",
    "    # Determinar decisão esperada\n",
    "    if eh_ficticio or dados_inconsistentes:\n",
    "        decisao_esperada = \"NEGADA\"\n",
    "        tipo_caso = \"alucinacao\"\n",
    "    elif num_defaults >= 2:\n",
    "        decisao_esperada = \"NEGADA\"\n",
    "        tipo_caso = \"multiplos_defaults\"\n",
    "    elif score < 600:\n",
    "        decisao_esperada = \"NEGADA\"\n",
    "        tipo_caso = \"score_baixo\"\n",
    "    elif score < 700:\n",
    "        decisao_esperada = \"ANALISE_GERENCIAL\"\n",
    "        tipo_caso = \"borderline\"\n",
    "    else:\n",
    "        decisao_esperada = \"APROVADA\"\n",
    "        tipo_caso = \"bom_cliente\"\n",
    "    \n",
    "    return {\n",
    "        \"decisao_esperada\": decisao_esperada,\n",
    "        \"tipo_caso\": tipo_caso,\n",
    "        \"eh_ficticio\": eh_ficticio,\n",
    "        \"dados_inconsistentes\": dados_inconsistentes\n",
    "    }\n",
    "\n",
    "\n",
    "# Criar dataset com anonimização\n",
    "dataset_blind = []\n",
    "\n",
    "random.seed(42)  # Para reprodutibilidade\n",
    "\n",
    "for i, cliente in enumerate(clientes_raw):\n",
    "    # 1. Determinar ground truth com dados ORIGINAIS\n",
    "    ground_truth = determinar_ground_truth(cliente)\n",
    "    \n",
    "    # 2. Anonimizar cliente para enviar ao modelo\n",
    "    cliente_anonimo = anonimizar_cliente(cliente, i)\n",
    "    \n",
    "    dataset_blind.append({\n",
    "        \"cliente_original\": cliente,  # Mantido apenas para referência interna\n",
    "        \"cliente_anonimo\": cliente_anonimo,  # Este vai para o modelo\n",
    "        \"ground_truth\": ground_truth,  # Não vai para o modelo\n",
    "        \"indice\": i\n",
    "    })\n",
    "\n",
    "print(f\"[OK] Dataset blind criado com {len(dataset_blind)} casos\")\n",
    "print(f\"\\nDistribuição (ground truth interno):\")\n",
    "print(f\"  - Alucinação: {sum(1 for d in dataset_blind if d['ground_truth']['tipo_caso'] == 'alucinacao')}\")\n",
    "print(f\"  - Bom cliente: {sum(1 for d in dataset_blind if d['ground_truth']['tipo_caso'] == 'bom_cliente')}\")\n",
    "print(f\"  - Score baixo: {sum(1 for d in dataset_blind if d['ground_truth']['tipo_caso'] == 'score_baixo')}\")\n",
    "print(f\"  - Borderline: {sum(1 for d in dataset_blind if d['ground_truth']['tipo_caso'] == 'borderline')}\")\n",
    "print(f\"  - Múltiplos defaults: {sum(1 for d in dataset_blind if d['ground_truth']['tipo_caso'] == 'multiplos_defaults')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DEMONSTRAÇÃO DA ANONIMIZAÇÃO\n",
      "======================================================================\n",
      "\n",
      "[ANTES] Dados ORIGINAIS (reveladores):\n",
      "  cliente_id: TEMP_ALUCINACAO_001\n",
      "  cpf: 999.999.999-99\n",
      "  score: 800\n",
      "\n",
      "[DEPOIS] Dados ANONIMIZADOS (enviados ao modelo):\n",
      "  cliente_id: CLI_A3121FBA\n",
      "  cpf: 265.423.511-40\n",
      "  score: 800\n",
      "\n",
      "[INTERNO] Ground Truth (NÃO vai para o modelo):\n",
      "  tipo_caso: alucinacao\n",
      "  decisao_esperada: NEGADA\n",
      "  eh_ficticio: True\n"
     ]
    }
   ],
   "source": [
    "# Demonstrar a anonimização\n",
    "print(\"=\"*70)\n",
    "print(\"DEMONSTRAÇÃO DA ANONIMIZAÇÃO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Encontrar um caso de alucinação para demonstrar\n",
    "caso_demo = None\n",
    "for item in dataset_blind:\n",
    "    if item[\"ground_truth\"][\"tipo_caso\"] == \"alucinacao\":\n",
    "        caso_demo = item\n",
    "        break\n",
    "\n",
    "if caso_demo:\n",
    "    print(\"\\n[ANTES] Dados ORIGINAIS (reveladores):\")\n",
    "    orig = caso_demo[\"cliente_original\"]\n",
    "    print(f\"  cliente_id: {orig.get('cliente_id', 'N/A')}\")\n",
    "    print(f\"  cpf: {orig.get('cpf', 'N/A')}\")\n",
    "    print(f\"  score: {orig.get('score_atual', 'N/A')}\")\n",
    "    \n",
    "    print(\"\\n[DEPOIS] Dados ANONIMIZADOS (enviados ao modelo):\")\n",
    "    anon = caso_demo[\"cliente_anonimo\"]\n",
    "    print(f\"  cliente_id: {anon.get('cliente_id', 'N/A')}\")\n",
    "    print(f\"  cpf: {anon.get('cpf', 'N/A')}\")\n",
    "    print(f\"  score: {anon.get('score_atual', 'N/A')}\")\n",
    "    \n",
    "    print(\"\\n[INTERNO] Ground Truth (NÃO vai para o modelo):\")\n",
    "    gt = caso_demo[\"ground_truth\"]\n",
    "    print(f\"  tipo_caso: {gt['tipo_caso']}\")\n",
    "    print(f\"  decisao_esperada: {gt['decisao_esperada']}\")\n",
    "    print(f\"  eh_ficticio: {gt['eh_ficticio']}\")\n",
    "else:\n",
    "    print(\"Nenhum caso de alucinação encontrado para demonstração.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Definindo Funções de Chamada à API (Blind Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Funções de prompt BLIND definidas\n"
     ]
    }
   ],
   "source": [
    "def criar_prompt_analise_blind(cliente_anonimo: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Cria o prompt para análise de crédito em modo BLIND.\n",
    "    \n",
    "    IMPORTANTE: Recebe apenas o cliente ANONIMIZADO.\n",
    "    Não há nenhuma pista sobre o tipo do cliente ou decisão esperada.\n",
    "    \"\"\"\n",
    "    cliente_json = json.dumps(cliente_anonimo, indent=2, ensure_ascii=False, default=str)\n",
    "    \n",
    "    return f\"\"\"# SOLICITAÇÃO DE ANÁLISE DE CRÉDITO\n",
    "\n",
    "## DADOS DO CLIENTE\n",
    "\n",
    "```json\n",
    "{cliente_json}\n",
    "```\n",
    "\n",
    "## TAREFA\n",
    "\n",
    "Analise este cliente conforme as políticas do banco.\n",
    "Determine se o crédito deve ser APROVADO, NEGADO ou encaminhado para ANÁLISE GERENCIAL.\n",
    "\n",
    "Responda em JSON:\n",
    "{{\n",
    "  \"decisao\": \"APROVADA\" | \"NEGADA\" | \"ANALISE_GERENCIAL\",\n",
    "  \"score\": <score do cliente>,\n",
    "  \"justificativa\": \"<explicação da decisão>\",\n",
    "  \"regras_aplicadas\": [\"<lista de regras aplicadas>\"]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def criar_system_prompt_blind(politicas: str) -> str:\n",
    "    \"\"\"\n",
    "    Cria o system prompt para teste blind.\n",
    "    \n",
    "    Não menciona alucinações ou clientes fictícios - o modelo deve\n",
    "    detectar problemas baseado nos dados financeiros.\n",
    "    \"\"\"\n",
    "    politicas_resumidas = politicas[:20000] if len(politicas) > 20000 else politicas\n",
    "    \n",
    "    return f\"\"\"Você é um analista de crédito do Banco Patriota S.A.\n",
    "\n",
    "Sua função é analisar solicitações de crédito e tomar decisões baseadas EXCLUSIVAMENTE nas políticas oficiais do banco.\n",
    "\n",
    "Atenção especial:\n",
    "- Verifique se os dados do cliente são consistentes entre si\n",
    "- Analise o histórico de defaults com cuidado\n",
    "- Considere a relação entre score, renda e endividamento\n",
    "\n",
    "---\n",
    "\n",
    "# POLÍTICAS DO BANCO\n",
    "\n",
    "{politicas_resumidas}\n",
    "\"\"\"\n",
    "\n",
    "print(\"[OK] Funções de prompt BLIND definidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Função de chamada ao modelo padrão definida\n"
     ]
    }
   ],
   "source": [
    "def extrair_json(texto: str) -> Dict:\n",
    "    \"\"\"Extrai JSON da resposta do modelo.\"\"\"\n",
    "    if \"```json\" in texto:\n",
    "        inicio = texto.find(\"```json\") + 7\n",
    "        fim = texto.find(\"```\", inicio)\n",
    "        if fim > inicio:\n",
    "            try:\n",
    "                return json.loads(texto[inicio:fim].strip())\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "    \n",
    "    inicio_brace = texto.find(\"{\")\n",
    "    if inicio_brace >= 0:\n",
    "        fim_brace = texto.rfind(\"}\")\n",
    "        if fim_brace > inicio_brace:\n",
    "            try:\n",
    "                return json.loads(texto[inicio_brace:fim_brace + 1])\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "    \n",
    "    return {\"erro\": \"Não foi possível extrair JSON\", \"texto_bruto\": texto[:500]}\n",
    "\n",
    "\n",
    "def chamar_modelo_padrao_blind(cliente_anonimo: Dict, system_prompt: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Chama o modelo PADRÃO com dados anonimizados.\n",
    "    \"\"\"\n",
    "    user_prompt = criar_prompt_analise_blind(cliente_anonimo)\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            max_tokens=2048,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        resposta_texto = response.choices[0].message.content\n",
    "        json_resposta = extrair_json(resposta_texto)\n",
    "        \n",
    "        return {\n",
    "            \"sucesso\": True,\n",
    "            \"resposta_bruta\": resposta_texto,\n",
    "            \"resposta_json\": json_resposta,\n",
    "            \"modo\": \"padrao_blind\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"sucesso\": False,\n",
    "            \"erro\": str(e),\n",
    "            \"modo\": \"padrao_blind\"\n",
    "        }\n",
    "\n",
    "print(\"[OK] Função de chamada ao modelo padrão definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Função de chamada ao modelo com ISR definida\n"
     ]
    }
   ],
   "source": [
    "def chamar_modelo_com_isr_blind(cliente_anonimo: Dict, cliente_original: Dict, system_prompt: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Chama o modelo COM validação ISR.\n",
    "    \n",
    "    IMPORTANTE: O ISR usa os dados ORIGINAIS para detectar inconsistências,\n",
    "    mas o modelo principal recebe dados ANONIMIZADOS.\n",
    "    \"\"\"\n",
    "    user_prompt = criar_prompt_analise_blind(cliente_anonimo)\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            max_tokens=2048,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        resposta_texto = response.choices[0].message.content\n",
    "        json_resposta = extrair_json(resposta_texto)\n",
    "        \n",
    "        decisao_inicial = json_resposta.get(\"decisao\", \"NEGADA\")\n",
    "        \n",
    "        # Validar com ISR (usa dados originais para detectar inconsistências)\n",
    "        isr_result = validar_com_isr_blind(cliente_original, cliente_anonimo, decisao_inicial, system_prompt)\n",
    "        \n",
    "        if isr_result[\"isr_decisao\"] == \"BLOQUEADO\":\n",
    "            json_resposta[\"decisao\"] = \"NEGADA\"\n",
    "            json_resposta[\"isr_bloqueou\"] = True\n",
    "            json_resposta[\"isr_motivo\"] = isr_result[\"motivo\"]\n",
    "        \n",
    "        return {\n",
    "            \"sucesso\": True,\n",
    "            \"resposta_bruta\": resposta_texto,\n",
    "            \"resposta_json\": json_resposta,\n",
    "            \"modo\": \"com_isr_blind\",\n",
    "            \"isr_usado\": True,\n",
    "            \"isr_metrics\": isr_result[\"metrics\"],\n",
    "            \"isr_valor\": isr_result[\"metrics\"].get(\"ISR\", 0)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"sucesso\": False,\n",
    "            \"erro\": str(e),\n",
    "            \"modo\": \"com_isr_blind\",\n",
    "            \"isr_usado\": True\n",
    "        }\n",
    "\n",
    "\n",
    "def validar_com_isr_blind(cliente_original: Dict, cliente_anonimo: Dict, decisao: str, system_prompt: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Implementa validação ISR para teste blind.\n",
    "    \n",
    "    ISR detecta:\n",
    "    1. Dados inconsistentes (score alto + defaults recentes)\n",
    "    2. Padrões anômalos nos dados financeiros\n",
    "    3. Instabilidade na decisão via permutações\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import math\n",
    "    \n",
    "    # Análise de inconsistências nos dados ORIGINAIS\n",
    "    score = cliente_original.get(\"score_atual\", 0)\n",
    "    defaults = cliente_original.get(\"defaults_historico\", []) or []\n",
    "    renda = cliente_original.get(\"renda_mensal\", 0)\n",
    "    endividamento = cliente_original.get(\"endividamento_atual\", 0)\n",
    "    \n",
    "    inconsistencias = []\n",
    "    \n",
    "    # Detectar score alto com defaults recentes\n",
    "    if score >= 750 and len(defaults) > 0:\n",
    "        for d in defaults:\n",
    "            data_default = str(d.get(\"data\", \"\"))\n",
    "            if \"2024\" in data_default or \"2025\" in data_default:\n",
    "                inconsistencias.append(\"Score alto com default recente\")\n",
    "                break\n",
    "    \n",
    "    # Detectar renda muito alta com score muito baixo\n",
    "    if renda > 30000 and score < 500:\n",
    "        inconsistencias.append(\"Renda alta incompatível com score baixo\")\n",
    "    \n",
    "    # Detectar endividamento impossível\n",
    "    if endividamento > 100:\n",
    "        inconsistencias.append(\"Endividamento acima de 100%\")\n",
    "    \n",
    "    # Se encontrou inconsistências graves, bloqueia\n",
    "    if inconsistencias:\n",
    "        return {\n",
    "            \"isr_decisao\": \"BLOQUEADO\",\n",
    "            \"motivo\": f\"Dados inconsistentes: {'; '.join(inconsistencias)}\",\n",
    "            \"metrics\": {\n",
    "                \"ISR\": 0.0,\n",
    "                \"B2T\": 999.0,\n",
    "                \"Delta\": 0.0,\n",
    "                \"P_Min\": 0.0,\n",
    "                \"instabilidade\": True,\n",
    "                \"inconsistencias\": inconsistencias\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # Verificar consistência com permutações\n",
    "    num_permutations = 4  # Reduzido para economizar API calls\n",
    "    probs = []\n",
    "    \n",
    "    for i in range(num_permutations):\n",
    "        prompt_verificacao = f\"\"\"\n",
    "        Baseado neste cliente e nas políticas do banco, a decisão \"{decisao}\" está correta?\n",
    "        \n",
    "        Cliente: {json.dumps(cliente_anonimo, default=str)}\n",
    "        \n",
    "        Responda apenas: Sim ou Não\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL_NAME,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Você é um auditor. Responda apenas Sim ou Não.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt_verificacao}\n",
    "                ],\n",
    "                max_tokens=10,\n",
    "                temperature=0.0,\n",
    "                logprobs=True,\n",
    "                top_logprobs=5\n",
    "            )\n",
    "            \n",
    "            if response.choices[0].logprobs and response.choices[0].logprobs.content:\n",
    "                top_tokens = response.choices[0].logprobs.content[0].top_logprobs\n",
    "                prob_sim = 0.0001\n",
    "                for token_obj in top_tokens:\n",
    "                    token_str = token_obj.token.strip().lower()\n",
    "                    if token_str in ['sim', 'yes', 's', 'y']:\n",
    "                        prob_sim = math.exp(token_obj.logprob)\n",
    "                        break\n",
    "                probs.append(prob_sim)\n",
    "            else:\n",
    "                probs.append(0.5)\n",
    "                \n",
    "        except Exception:\n",
    "            probs.append(0.5)\n",
    "    \n",
    "    # Calcular métricas ISR\n",
    "    probs_array = np.array(probs)\n",
    "    p_mean = np.mean(probs_array)\n",
    "    p_min = np.min(probs_array)\n",
    "    \n",
    "    if p_min < 0.2:\n",
    "        isr_decisao = \"BLOQUEADO\"\n",
    "        motivo = f\"Instabilidade detectada (P_min={p_min:.4f})\"\n",
    "    else:\n",
    "        isr_decisao = \"APROVADO\"\n",
    "        motivo = f\"Confiança adequada (P_mean={p_mean:.4f})\"\n",
    "    \n",
    "    # Calcular ISR\n",
    "    target = 0.95\n",
    "    epsilon = 1e-9\n",
    "    \n",
    "    if p_min > epsilon:\n",
    "        b2t = np.log(target / max(p_min, 0.125))\n",
    "        delta = np.mean([np.log(max(p_mean, epsilon) / max(p, epsilon)) for p in probs_array])\n",
    "        isr = delta / max(b2t, epsilon) if b2t > 0 else 10.0\n",
    "    else:\n",
    "        isr = 0.0\n",
    "        b2t = 999.0\n",
    "        delta = 0.0\n",
    "    \n",
    "    return {\n",
    "        \"isr_decisao\": isr_decisao,\n",
    "        \"motivo\": motivo,\n",
    "        \"metrics\": {\n",
    "            \"ISR\": round(float(isr), 4),\n",
    "            \"B2T\": round(float(b2t), 4),\n",
    "            \"Delta\": round(float(delta), 4),\n",
    "            \"P_Mean\": round(float(p_mean), 4),\n",
    "            \"P_Min\": round(float(p_min), 4),\n",
    "            \"instabilidade\": bool(p_min < 0.2)\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"[OK] Função de chamada ao modelo com ISR definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Executando Teste Blind\n",
    "\n",
    "**IMPORTANTE:** O modelo recebe apenas dados anonimizados. Nenhuma pista sobre tipo ou decisão esperada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] System prompt BLIND criado: 20386 caracteres\n"
     ]
    }
   ],
   "source": [
    "# Preparar system prompt\n",
    "SYSTEM_PROMPT_BLIND = criar_system_prompt_blind(POLITICAS_BANCO)\n",
    "\n",
    "print(f\"[OK] System prompt BLIND criado: {len(SYSTEM_PROMPT_BLIND)} caracteres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Selecionados 22 casos para teste BLIND\n",
      "\n",
      "Distribuição (interno):\n",
      "  - alucinacao: 2\n",
      "  - score_baixo: 6\n",
      "  - borderline: 5\n",
      "  - bom_cliente: 6\n",
      "  - multiplos_defaults: 3\n"
     ]
    }
   ],
   "source": [
    "# Selecionar casos para teste (balanceado por tipo)\n",
    "casos_teste = []\n",
    "\n",
    "for tipo in [\"alucinacao\", \"score_baixo\", \"borderline\", \"bom_cliente\", \"multiplos_defaults\"]:\n",
    "    casos_tipo = [c for c in dataset_blind if c[\"ground_truth\"][\"tipo_caso\"] == tipo]\n",
    "    casos_teste.extend(casos_tipo[:6])  # 6 de cada tipo = 30 total\n",
    "\n",
    "# Embaralhar para evitar padrões\n",
    "random.shuffle(casos_teste)\n",
    "\n",
    "print(f\"[OK] Selecionados {len(casos_teste)} casos para teste BLIND\")\n",
    "print(f\"\\nDistribuição (interno):\")\n",
    "for tipo in [\"alucinacao\", \"score_baixo\", \"borderline\", \"bom_cliente\", \"multiplos_defaults\"]:\n",
    "    count = sum(1 for c in casos_teste if c[\"ground_truth\"][\"tipo_caso\"] == tipo)\n",
    "    print(f\"  - {tipo}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando execução dos testes BLIND...\n",
      "======================================================================\n",
      "[INFO] Modelo recebe dados ANONIMIZADOS\n",
      "[INFO] Nenhuma pista sobre tipo ou decisão esperada\n",
      "======================================================================\n",
      "\n",
      "[1/22] ID Anônimo: CLI_71438261\n",
      "    Score: 750\n",
      "    -> Modelo padrão... APROVADA\n",
      "    -> Modelo com ISR... APROVADA (ISR: 10.0000)\n",
      "\n",
      "[2/22] ID Anônimo: CLI_C4077072\n",
      "    Score: 820\n",
      "    -> Modelo padrão... NEGADA\n",
      "    -> Modelo com ISR... NEGADA (ISR: 0.0623)\n",
      "\n",
      "[3/22] ID Anônimo: CLI_F0F254F9\n",
      "    Score: 480\n",
      "    -> Modelo padrão... NEGADA\n",
      "    -> Modelo com ISR... NEGADA (ISR: 10.0000)\n",
      "\n",
      "[4/22] ID Anônimo: CLI_FFC48D59\n",
      "    Score: 620\n",
      "    -> Modelo padrão... NEGADA\n",
      "    -> Modelo com ISR... NEGADA (ISR: 0.0234)\n",
      "\n",
      "[5/22] ID Anônimo: CLI_7337F832\n",
      "    Score: 590\n",
      "    -> Modelo padrão... NEGADA\n",
      "    -> Modelo com ISR... NEGADA (ISR: 0.0000)\n",
      "\n",
      "[6/22] ID Anônimo: CLI_3F64C458\n",
      "    Score: 850\n",
      "    -> Modelo padrão... APROVADA\n",
      "    -> Modelo com ISR... APROVADA (ISR: 10.0000)\n",
      "\n",
      "[7/22] ID Anônimo: CLI_D2FE6106\n",
      "    Score: 780\n",
      "    -> Modelo padrão... APROVADA\n",
      "    -> Modelo com ISR... APROVADA (ISR: 10.0000)\n",
      "\n",
      "[8/22] ID Anônimo: CLI_B456C6E2\n",
      "    Score: 795\n",
      "    -> Modelo padrão... APROVADA\n",
      "    -> Modelo com ISR... APROVADA (ISR: 10.0000)\n",
      "\n",
      "[9/22] ID Anônimo: CLI_4AFF3E01\n",
      "    Score: 720\n",
      "    -> Modelo padrão... APROVADA\n",
      "    -> Modelo com ISR... APROVADA (ISR: 10.0000)\n",
      "\n",
      "[10/22] ID Anônimo: CLI_1E29E54F\n",
      "    Score: 920\n",
      "    -> Modelo padrão... NEGADA\n",
      "    -> Modelo com ISR... NEGADA (ISR: 0.0018)\n",
      "\n",
      "[11/22] ID Anônimo: CLI_F8D52432\n",
      "    Score: 750\n",
      "    -> Modelo padrão... NEGADA\n",
      "    -> Modelo com ISR... NEGADA (ISR: 0.0210)\n",
      "\n",
      "[12/22] ID Anônimo: CLI_6C2D7B20\n",
      "    Score: 520\n",
      "    -> Modelo padrão... NEGADA\n",
      "    -> Modelo com ISR... NEGADA (ISR: 10.0000)\n",
      "\n",
      "[13/22] ID Anônimo: CLI_1665DAA1\n",
      "    Score: 450\n",
      "    -> Modelo padrão... NEGADA\n",
      "    -> Modelo com ISR... NEGADA (ISR: 10.0000)\n",
      "\n",
      "[14/22] ID Anônimo: CLI_0C96F4E0\n",
      "    Score: 680\n",
      "    -> Modelo padrão... ANALISE_GERENCIAL\n",
      "    -> Modelo com ISR... ANALISE_GERENCIAL (ISR: 10.0000)\n",
      "\n",
      "[15/22] ID Anônimo: CLI_A3121FBA\n",
      "    Score: 800\n",
      "    -> Modelo padrão... NEGADA\n",
      "    -> Modelo com ISR... NEGADA (ISR: 0.0027)\n",
      "\n",
      "[16/22] ID Anônimo: CLI_ED29934F\n",
      "    Score: 750\n",
      "    -> Modelo padrão... NEGADA\n",
      "    -> Modelo com ISR... NEGADA (ISR: 0.0150)\n",
      "\n",
      "[17/22] ID Anônimo: CLI_60802294\n",
      "    Score: 550\n",
      "    -> Modelo padrão... NEGADA\n",
      "    -> Modelo com ISR... NEGADA (ISR: 0.0125)\n",
      "\n",
      "[18/22] ID Anônimo: CLI_2EF1DAF5\n",
      "    Score: 695\n",
      "    -> Modelo padrão... ANALISE_GERENCIAL\n",
      "    -> Modelo com ISR... ANALISE_GERENCIAL (ISR: 10.0000)\n",
      "\n",
      "[19/22] ID Anônimo: CLI_0A1FBAD9\n",
      "    Score: 650\n",
      "    -> Modelo padrão... ANALISE_GERENCIAL\n",
      "    -> Modelo com ISR... NEGADA (ISR: 0.0101)\n",
      "\n",
      "[20/22] ID Anônimo: CLI_4AAD6F85\n",
      "    Score: 799\n",
      "    -> Modelo padrão... APROVADA\n",
      "    -> Modelo com ISR... APROVADA (ISR: 10.0000)\n",
      "\n",
      "[21/22] ID Anônimo: CLI_AC9C87CC\n",
      "    Score: 380\n",
      "    -> Modelo padrão... NEGADA\n",
      "    -> Modelo com ISR... NEGADA (ISR: 10.0000)\n",
      "\n",
      "[22/22] ID Anônimo: CLI_7508B617\n",
      "    Score: 699\n",
      "    -> Modelo padrão... ANALISE_GERENCIAL\n",
      "    -> Modelo com ISR... ANALISE_GERENCIAL (ISR: 10.0000)\n",
      "\n",
      "======================================================================\n",
      "[OK] Execução BLIND concluída!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Executar testes\n",
    "resultados_padrao = []\n",
    "resultados_isr = []\n",
    "\n",
    "print(\"Iniciando execução dos testes BLIND...\")\n",
    "print(\"=\"*70)\n",
    "print(\"[INFO] Modelo recebe dados ANONIMIZADOS\")\n",
    "print(\"[INFO] Nenhuma pista sobre tipo ou decisão esperada\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, item in enumerate(casos_teste):\n",
    "    cliente_anonimo = item[\"cliente_anonimo\"]\n",
    "    cliente_original = item[\"cliente_original\"]\n",
    "    ground_truth = item[\"ground_truth\"]\n",
    "    \n",
    "    esperado = ground_truth[\"decisao_esperada\"]\n",
    "    tipo_caso = ground_truth[\"tipo_caso\"]\n",
    "    \n",
    "    # Log interno (não vai para o modelo)\n",
    "    print(f\"\\n[{i+1}/{len(casos_teste)}] ID Anônimo: {cliente_anonimo['cliente_id']}\")\n",
    "    print(f\"    Score: {cliente_anonimo.get('score_atual', 'N/A')}\")\n",
    "    \n",
    "    # Modelo Padrão (recebe dados anonimizados)\n",
    "    print(f\"    -> Modelo padrão...\", end=\" \")\n",
    "    resp_padrao = chamar_modelo_padrao_blind(cliente_anonimo, SYSTEM_PROMPT_BLIND)\n",
    "    \n",
    "    if resp_padrao[\"sucesso\"]:\n",
    "        decisao_padrao = resp_padrao[\"resposta_json\"].get(\"decisao\", \"ERRO\")\n",
    "        print(f\"{decisao_padrao}\")\n",
    "    else:\n",
    "        decisao_padrao = \"ERRO\"\n",
    "        print(f\"ERRO\")\n",
    "    \n",
    "    resultados_padrao.append({\n",
    "        \"cliente_id_anonimo\": cliente_anonimo[\"cliente_id\"],\n",
    "        \"cliente_id_original\": cliente_original.get(\"cliente_id\", \"N/A\"),\n",
    "        \"score\": cliente_anonimo.get(\"score_atual\"),\n",
    "        \"tipo_caso\": tipo_caso,\n",
    "        \"esperado\": esperado,\n",
    "        \"obtido\": decisao_padrao,\n",
    "        \"eh_ficticio\": ground_truth[\"eh_ficticio\"],\n",
    "        \"acertou\": decisao_padrao == esperado\n",
    "    })\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Agente ISR\n",
    "    print(f\"    -> Modelo com ISR...\", end=\" \")\n",
    "    resp_isr = chamar_modelo_com_isr_blind(cliente_anonimo, cliente_original, SYSTEM_PROMPT_BLIND)\n",
    "    \n",
    "    if resp_isr[\"sucesso\"]:\n",
    "        decisao_isr = resp_isr[\"resposta_json\"].get(\"decisao\", \"ERRO\")\n",
    "        isr_valor = resp_isr.get(\"isr_valor\", 0)\n",
    "        print(f\"{decisao_isr} (ISR: {isr_valor:.4f})\")\n",
    "    else:\n",
    "        decisao_isr = \"ERRO\"\n",
    "        isr_valor = 0\n",
    "        print(f\"ERRO\")\n",
    "    \n",
    "    resultados_isr.append({\n",
    "        \"cliente_id_anonimo\": cliente_anonimo[\"cliente_id\"],\n",
    "        \"cliente_id_original\": cliente_original.get(\"cliente_id\", \"N/A\"),\n",
    "        \"score\": cliente_anonimo.get(\"score_atual\"),\n",
    "        \"tipo_caso\": tipo_caso,\n",
    "        \"esperado\": esperado,\n",
    "        \"obtido\": decisao_isr,\n",
    "        \"eh_ficticio\": ground_truth[\"eh_ficticio\"],\n",
    "        \"acertou\": decisao_isr == esperado,\n",
    "        \"isr_valor\": isr_valor,\n",
    "        \"isr_metrics\": resp_isr.get(\"isr_metrics\", {})\n",
    "    })\n",
    "    \n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"[OK] Execução BLIND concluída!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Calculando Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Métricas calculadas!\n"
     ]
    }
   ],
   "source": [
    "def calcular_metricas(resultados: List[Dict]) -> Dict[str, Any]:\n",
    "    \"\"\"Calcula métricas de ML.\"\"\"\n",
    "    \n",
    "    def to_binary(decisao: str) -> int:\n",
    "        return 1 if decisao == \"APROVADA\" else 0\n",
    "    \n",
    "    def normalizar(decisao: str) -> str:\n",
    "        if decisao in [\"NEGADA\", \"RECUSADA\"]:\n",
    "            return \"NEGADA\"\n",
    "        return decisao\n",
    "    \n",
    "    valid_resultados = [r for r in resultados if r[\"obtido\"] != \"ERRO\"]\n",
    "    \n",
    "    if not valid_resultados:\n",
    "        return {\"erro\": \"Nenhum resultado válido\"}\n",
    "    \n",
    "    y_true = [to_binary(normalizar(r[\"esperado\"])) for r in valid_resultados]\n",
    "    y_pred = [to_binary(normalizar(r[\"obtido\"])) for r in valid_resultados]\n",
    "    \n",
    "    tp = sum(1 for t, p in zip(y_true, y_pred) if t == 1 and p == 1)\n",
    "    tn = sum(1 for t, p in zip(y_true, y_pred) if t == 0 and p == 0)\n",
    "    fp = sum(1 for t, p in zip(y_true, y_pred) if t == 0 and p == 1)\n",
    "    fn = sum(1 for t, p in zip(y_true, y_pred) if t == 1 and p == 0)\n",
    "    \n",
    "    total = len(valid_resultados)\n",
    "    \n",
    "    accuracy = (tp + tn) / total if total > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    casos_ficticios = [r for r in valid_resultados if r[\"eh_ficticio\"]]\n",
    "    alucinacoes_detectadas = sum(1 for r in casos_ficticios if r[\"obtido\"] in [\"NEGADA\", \"RECUSADA\"])\n",
    "    taxa_deteccao_alucinacao = alucinacoes_detectadas / len(casos_ficticios) if casos_ficticios else 1.0\n",
    "    \n",
    "    return {\n",
    "        \"confusion_matrix\": {\"TP\": int(tp), \"TN\": int(tn), \"FP\": int(fp), \"FN\": int(fn)},\n",
    "        \"accuracy\": float(accuracy),\n",
    "        \"precision\": float(precision),\n",
    "        \"recall\": float(recall),\n",
    "        \"f1_score\": float(f1),\n",
    "        \"false_positives\": int(fp),\n",
    "        \"taxa_deteccao_alucinacao\": float(taxa_deteccao_alucinacao),\n",
    "        \"total_ficticios\": int(len(casos_ficticios)),\n",
    "        \"ficticios_detectados\": int(alucinacoes_detectadas),\n",
    "        \"total_validos\": int(total)\n",
    "    }\n",
    "\n",
    "metricas_padrao = calcular_metricas(resultados_padrao)\n",
    "metricas_isr = calcular_metricas(resultados_isr)\n",
    "\n",
    "print(\"[OK] Métricas calculadas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Resultados: Modelo Padrão (Blind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODELO PADRÃO - BLIND TEST (sem pistas nos dados)\n",
      "======================================================================\n",
      "\n",
      "Matriz de Confusão:\n",
      "  +------------------+------------------+\n",
      "  |  TP =   6       |  FN =   0       |\n",
      "  | (Aprovou certo)  | (Perdeu cliente) |\n",
      "  +------------------+------------------+\n",
      "  |  FP =   0       |  TN =  16       |\n",
      "  | (RISCO!)         | (Negou certo)    |\n",
      "  +------------------+------------------+\n",
      "\n",
      "Métricas:\n",
      "  Accuracy:  100.0%\n",
      "  Precision: 100.0%\n",
      "  Recall:    100.0%\n",
      "  F1-Score:  100.0%\n",
      "\n",
      "[CRÍTICO] Detecção de Alucinação (sem pistas):\n",
      "  Clientes fictícios: 2\n",
      "  Detectados: 2\n",
      "  Taxa de detecção: 100.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODELO PADRÃO - BLIND TEST (sem pistas nos dados)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if \"erro\" not in metricas_padrao:\n",
    "    cm = metricas_padrao[\"confusion_matrix\"]\n",
    "    print(f\"\\nMatriz de Confusão:\")\n",
    "    print(f\"  +------------------+------------------+\")\n",
    "    print(f\"  |  TP = {cm['TP']:>3}       |  FN = {cm['FN']:>3}       |\")\n",
    "    print(f\"  | (Aprovou certo)  | (Perdeu cliente) |\")\n",
    "    print(f\"  +------------------+------------------+\")\n",
    "    print(f\"  |  FP = {cm['FP']:>3}       |  TN = {cm['TN']:>3}       |\")\n",
    "    print(f\"  | (RISCO!)         | (Negou certo)    |\")\n",
    "    print(f\"  +------------------+------------------+\")\n",
    "    \n",
    "    print(f\"\\nMétricas:\")\n",
    "    print(f\"  Accuracy:  {metricas_padrao['accuracy']:.1%}\")\n",
    "    print(f\"  Precision: {metricas_padrao['precision']:.1%}\")\n",
    "    print(f\"  Recall:    {metricas_padrao['recall']:.1%}\")\n",
    "    print(f\"  F1-Score:  {metricas_padrao['f1_score']:.1%}\")\n",
    "    \n",
    "    print(f\"\\n[CRÍTICO] Detecção de Alucinação (sem pistas):\")\n",
    "    print(f\"  Clientes fictícios: {metricas_padrao['total_ficticios']}\")\n",
    "    print(f\"  Detectados: {metricas_padrao['ficticios_detectados']}\")\n",
    "    print(f\"  Taxa de detecção: {metricas_padrao['taxa_deteccao_alucinacao']:.1%}\")\n",
    "    \n",
    "    if metricas_padrao[\"false_positives\"] > 0:\n",
    "        print(f\"\\n[ALERTA] {metricas_padrao['false_positives']} APROVAÇÕES INDEVIDAS!\")\n",
    "else:\n",
    "    print(f\"ERRO: {metricas_padrao['erro']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Resultados: Agente ISR (Blind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "AGENTE COM ISR - BLIND TEST\n",
      "======================================================================\n",
      "\n",
      "Matriz de Confusão:\n",
      "  +------------------+------------------+\n",
      "  |  TP =   6       |  FN =   0       |\n",
      "  | (Aprovou certo)  | (Perdeu cliente) |\n",
      "  +------------------+------------------+\n",
      "  |  FP =   0       |  TN =  16       |\n",
      "  | (RISCO!)         | (Negou certo)    |\n",
      "  +------------------+------------------+\n",
      "\n",
      "Métricas:\n",
      "  Accuracy:  100.0%\n",
      "  Precision: 100.0%\n",
      "  Recall:    100.0%\n",
      "  F1-Score:  100.0%\n",
      "\n",
      "[PROTEÇÃO] Detecção de Alucinação:\n",
      "  Clientes fictícios: 2\n",
      "  Detectados: 2\n",
      "  Taxa de detecção: 100.0%\n",
      "\n",
      "[SUCESSO] ZERO aprovações indevidas!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"AGENTE COM ISR - BLIND TEST\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if \"erro\" not in metricas_isr:\n",
    "    cm = metricas_isr[\"confusion_matrix\"]\n",
    "    print(f\"\\nMatriz de Confusão:\")\n",
    "    print(f\"  +------------------+------------------+\")\n",
    "    print(f\"  |  TP = {cm['TP']:>3}       |  FN = {cm['FN']:>3}       |\")\n",
    "    print(f\"  | (Aprovou certo)  | (Perdeu cliente) |\")\n",
    "    print(f\"  +------------------+------------------+\")\n",
    "    print(f\"  |  FP = {cm['FP']:>3}       |  TN = {cm['TN']:>3}       |\")\n",
    "    print(f\"  | (RISCO!)         | (Negou certo)    |\")\n",
    "    print(f\"  +------------------+------------------+\")\n",
    "    \n",
    "    print(f\"\\nMétricas:\")\n",
    "    print(f\"  Accuracy:  {metricas_isr['accuracy']:.1%}\")\n",
    "    print(f\"  Precision: {metricas_isr['precision']:.1%}\")\n",
    "    print(f\"  Recall:    {metricas_isr['recall']:.1%}\")\n",
    "    print(f\"  F1-Score:  {metricas_isr['f1_score']:.1%}\")\n",
    "    \n",
    "    print(f\"\\n[PROTEÇÃO] Detecção de Alucinação:\")\n",
    "    print(f\"  Clientes fictícios: {metricas_isr['total_ficticios']}\")\n",
    "    print(f\"  Detectados: {metricas_isr['ficticios_detectados']}\")\n",
    "    print(f\"  Taxa de detecção: {metricas_isr['taxa_deteccao_alucinacao']:.1%}\")\n",
    "    \n",
    "    if metricas_isr[\"false_positives\"] == 0:\n",
    "        print(f\"\\n[SUCESSO] ZERO aprovações indevidas!\")\n",
    "    else:\n",
    "        print(f\"\\n[ATENÇÃO] {metricas_isr['false_positives']} aprovações indevidas\")\n",
    "else:\n",
    "    print(f\"ERRO: {metricas_isr['erro']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Comparação Final (Blind Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPARAÇÃO BLIND TEST: MODELO PADRÃO vs AGENTE ISR\n",
      "================================================================================\n",
      "\n",
      "[INFO] Dados ANONIMIZADOS - Sem vazamento de informação\n",
      "[INFO] O modelo NÃO recebeu pistas sobre tipo ou decisão esperada\n",
      "\n",
      "Métrica                          Modelo Padrão      Agente ISR       Diferença\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy                               100.0%         100.0%          +0.0%\n",
      "Precision                              100.0%         100.0%          +0.0%\n",
      "Recall                                 100.0%         100.0%          +0.0%\n",
      "F1-Score                               100.0%         100.0%          +0.0%\n",
      "--------------------------------------------------------------------------------\n",
      "False Positives (RISCO!)                     0               0              +0\n",
      "Detecção de Alucinação                 100.0%         100.0%          +0.0%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPARAÇÃO BLIND TEST: MODELO PADRÃO vs AGENTE ISR\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n[INFO] Dados ANONIMIZADOS - Sem vazamento de informação\")\n",
    "print(\"[INFO] O modelo NÃO recebeu pistas sobre tipo ou decisão esperada\\n\")\n",
    "\n",
    "if \"erro\" not in metricas_padrao and \"erro\" not in metricas_isr:\n",
    "    print(f\"{'Métrica':<30} {'Modelo Padrão':>15} {'Agente ISR':>15} {'Diferença':>15}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    diff_acc = metricas_isr['accuracy'] - metricas_padrao['accuracy']\n",
    "    print(f\"{'Accuracy':<30} {metricas_padrao['accuracy']:>14.1%} {metricas_isr['accuracy']:>14.1%} {diff_acc:>+14.1%}\")\n",
    "    \n",
    "    diff_prec = metricas_isr['precision'] - metricas_padrao['precision']\n",
    "    print(f\"{'Precision':<30} {metricas_padrao['precision']:>14.1%} {metricas_isr['precision']:>14.1%} {diff_prec:>+14.1%}\")\n",
    "    \n",
    "    diff_rec = metricas_isr['recall'] - metricas_padrao['recall']\n",
    "    print(f\"{'Recall':<30} {metricas_padrao['recall']:>14.1%} {metricas_isr['recall']:>14.1%} {diff_rec:>+14.1%}\")\n",
    "    \n",
    "    diff_f1 = metricas_isr['f1_score'] - metricas_padrao['f1_score']\n",
    "    print(f\"{'F1-Score':<30} {metricas_padrao['f1_score']:>14.1%} {metricas_isr['f1_score']:>14.1%} {diff_f1:>+14.1%}\")\n",
    "    \n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    diff_fp = metricas_isr['false_positives'] - metricas_padrao['false_positives']\n",
    "    print(f\"{'False Positives (RISCO!)':<30} {metricas_padrao['false_positives']:>15} {metricas_isr['false_positives']:>15} {diff_fp:>+15}\")\n",
    "    \n",
    "    diff_aluc = metricas_isr['taxa_deteccao_alucinacao'] - metricas_padrao['taxa_deteccao_alucinacao']\n",
    "    print(f\"{'Detecção de Alucinação':<30} {metricas_padrao['taxa_deteccao_alucinacao']:>14.1%} {metricas_isr['taxa_deteccao_alucinacao']:>14.1%} {diff_aluc:>+14.1%}\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"Erro ao calcular métricas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Análise Detalhada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ANÁLISE: ERROS DO MODELO PADRÃO (sem pistas)\n",
      "================================================================================\n",
      "\n",
      "Total de erros: 1\n",
      "\n",
      "Detalhamento:\n",
      "\n",
      "  ID Original: TEST_BORDERLINE_001\n",
      "  ID Anônimo: CLI_FFC48D59\n",
      "  Tipo (interno): borderline\n",
      "  Score: 620\n",
      "  Esperado: ANALISE_GERENCIAL | Obtido: NEGADA\n"
     ]
    }
   ],
   "source": [
    "# Mostrar casos onde o modelo errou (sem ter pistas)\n",
    "print(\"=\"*80)\n",
    "print(\"ANÁLISE: ERROS DO MODELO PADRÃO (sem pistas)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "erros_padrao = [r for r in resultados_padrao if not r[\"acertou\"]]\n",
    "\n",
    "if erros_padrao:\n",
    "    print(f\"\\nTotal de erros: {len(erros_padrao)}\")\n",
    "    print(\"\\nDetalhamento:\")\n",
    "    \n",
    "    for erro in erros_padrao[:10]:  # Mostrar até 10\n",
    "        print(f\"\\n  ID Original: {erro['cliente_id_original']}\")\n",
    "        print(f\"  ID Anônimo: {erro['cliente_id_anonimo']}\")\n",
    "        print(f\"  Tipo (interno): {erro['tipo_caso']}\")\n",
    "        print(f\"  Score: {erro['score']}\")\n",
    "        print(f\"  Esperado: {erro['esperado']} | Obtido: {erro['obtido']}\")\n",
    "        if erro['eh_ficticio']:\n",
    "            print(f\"  [CRÍTICO] Era cliente fictício e foi aprovado!\")\n",
    "else:\n",
    "    print(\"\\nNenhum erro do modelo padrão!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CASOS ONDE ISR FEZ DIFERENÇA\n",
      "================================================================================\n",
      "\n",
      "Cliente: TEST_BORDERLINE_002\n",
      "  Tipo: borderline\n",
      "  Esperado: ANALISE_GERENCIAL\n",
      "  Padrão:   ANALISE_GERENCIAL (OK)\n",
      "  ISR:      NEGADA (ERRO)\n"
     ]
    }
   ],
   "source": [
    "# Casos onde ISR fez diferença\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CASOS ONDE ISR FEZ DIFERENÇA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "diferenca_casos = []\n",
    "for rp, ri in zip(resultados_padrao, resultados_isr):\n",
    "    if rp[\"obtido\"] != ri[\"obtido\"]:\n",
    "        diferenca_casos.append({\n",
    "            \"cliente_id_original\": rp[\"cliente_id_original\"],\n",
    "            \"tipo_caso\": rp[\"tipo_caso\"],\n",
    "            \"esperado\": rp[\"esperado\"],\n",
    "            \"padrao\": rp[\"obtido\"],\n",
    "            \"isr\": ri[\"obtido\"],\n",
    "            \"padrao_acertou\": rp[\"acertou\"],\n",
    "            \"isr_acertou\": ri[\"acertou\"],\n",
    "            \"eh_ficticio\": rp[\"eh_ficticio\"]\n",
    "        })\n",
    "\n",
    "if diferenca_casos:\n",
    "    for caso in diferenca_casos:\n",
    "        print(f\"\\nCliente: {caso['cliente_id_original']}\")\n",
    "        print(f\"  Tipo: {caso['tipo_caso']}\")\n",
    "        print(f\"  Esperado: {caso['esperado']}\")\n",
    "        print(f\"  Padrão:   {caso['padrao']} ({'OK' if caso['padrao_acertou'] else 'ERRO'})\")\n",
    "        print(f\"  ISR:      {caso['isr']} ({'OK' if caso['isr_acertou'] else 'ERRO'})\")\n",
    "        \n",
    "        if caso['eh_ficticio'] and caso['isr_acertou'] and not caso['padrao_acertou']:\n",
    "            print(f\"  [ISR PROTEGEU] Bloqueou cliente fictício!\")\n",
    "else:\n",
    "    print(\"\\nNenhuma diferença entre os modelos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Salvando Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar resultados\n",
    "output_dir = PROJECT_ROOT / \"outputs\" / \"notebook_results\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_file = output_dir / f\"comparacao_blind_test_{timestamp}.json\"\n",
    "\n",
    "def limpar_para_json(resultados):\n",
    "    limpos = []\n",
    "    for r in resultados:\n",
    "        limpo = {}\n",
    "        for k, v in r.items():\n",
    "            if k == \"resposta_completa\":\n",
    "                continue\n",
    "            if hasattr(v, 'item'):\n",
    "                limpo[k] = v.item()\n",
    "            elif isinstance(v, bool):\n",
    "                limpo[k] = bool(v)\n",
    "            elif isinstance(v, dict):\n",
    "                limpo[k] = {kk: (vv.item() if hasattr(vv, 'item') else bool(vv) if isinstance(vv, (bool, type(None))) else vv) for kk, vv in v.items()}\n",
    "            else:\n",
    "                limpo[k] = v\n",
    "        limpos.append(limpo)\n",
    "    return limpos\n",
    "\n",
    "dados_salvar = {\n",
    "    \"metadata\": {\n",
    "        \"timestamp\": timestamp,\n",
    "        \"modelo\": MODEL_NAME,\n",
    "        \"versao\": \"4.0-blind-test\",\n",
    "        \"total_casos\": len(casos_teste),\n",
    "        \"descricao\": \"Teste cego: dados anonimizados, sem vazamento de informação\"\n",
    "    },\n",
    "    \"resultados_padrao\": limpar_para_json(resultados_padrao),\n",
    "    \"resultados_isr\": limpar_para_json(resultados_isr),\n",
    "    \"metricas_padrao\": metricas_padrao,\n",
    "    \"metricas_isr\": metricas_isr\n",
    "}\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(dados_salvar, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"[OK] Resultados salvos em: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-33",
   "metadata": {},
   "source": [
    "---\n",
    "## 13. Conclusões (Blind Test)\n",
    "\n",
    "### O que esta versão testa\n",
    "\n",
    "| Aspecto | Versão 3 (Zero-Shot) | Versão 4 (Blind Test) |\n",
    "|---------|---------------------|----------------------|\n",
    "| Cliente ID | `TEMP_ALUCINACAO_001` | `CLI_A3F2B1C4` |\n",
    "| CPF | `999.999.999-99` | CPF válido gerado |\n",
    "| Tipo no log | Visível | Apenas interno |\n",
    "| Data leakage | Possível | Eliminado |\n",
    "\n",
    "### Interpretação dos Resultados\n",
    "\n",
    "1. **Se performance caiu muito**: O modelo na v3 estava usando as pistas (data leakage)\n",
    "2. **Se performance similar**: O modelo realmente analisa dados financeiros\n",
    "3. **ISR continua útil**: Detecta inconsistências nos dados originais\n",
    "\n",
    "### Recomendações\n",
    "\n",
    "1. **Use sempre blind test** para avaliações justas\n",
    "2. **Compare v3 vs v4** para medir o impacto do data leakage\n",
    "3. **ISR detecta por dados** não por pistas nos identificadores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
