{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Avaliação Zero-Shot: Modelo Padrão vs Agente com ISR\n",
    "\n",
    "## Sextant Banking Edition - Testes com API Real (Zero-Shot)\n",
    "\n",
    "**Autor:** SK-Crossroads  \n",
    "**Data:** Janeiro 2026  \n",
    "**Versão:** 3.0 (Zero-Shot - Apenas Políticas)\n",
    "\n",
    "---\n",
    "\n",
    "### Objetivo deste Notebook\n",
    "\n",
    "Este notebook demonstra a **comparação entre duas abordagens** para decisões de crédito bancário usando a **API real da OpenAI** (modelo gpt-4o-mini) em modo **ZERO-SHOT**:\n",
    "\n",
    "| Abordagem | Descrição | Problema |\n",
    "|-----------|-----------|----------|\n",
    "| **Modelo Padrão** | Modelo de linguagem sem validação ISR | Pode alucinar e aprovar clientes inexistentes |\n",
    "| **Agente com ISR** | Modelo + Information Sufficiency Rating | Valida se há informação suficiente antes de decidir |\n",
    "\n",
    "### Diferencial desta versão (Zero-Shot):\n",
    "\n",
    "- **SEM prompt de instruções detalhadas** - O modelo recebe APENAS as políticas do banco\n",
    "- **Avalia capacidade de interpretação** do modelo sem guia passo-a-passo\n",
    "- **Teste de robustez** - Como o modelo lida com regras complexas sem exemplos\n",
    "- **Políticas do banco** (`banco_politicas_diretrizes.md`) como ÚNICO contexto\n",
    "- **ISR Auditor** para validação de suficiência informacional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup do Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Diretório do projeto: /home/dumoura/Kunumi/Hallucinations_ISR_V4\n",
      "[OK] Feature dir existe: True\n",
      "[OK] Políticas existem: True\n",
      "\n",
      "[INFO] Versão: ZERO-SHOT (sem prompt de instruções)\n"
     ]
    }
   ],
   "source": [
    "# Imports necessários\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Encontra o diretório raiz do projeto de forma robusta\n",
    "def find_project_root():\n",
    "    \"\"\"Encontra o diretório raiz do projeto procurando por arquivos marcadores.\"\"\"\n",
    "    current = Path.cwd()\n",
    "    \n",
    "    # Se estamos na pasta notebooks, sobe um nível\n",
    "    if current.name == \"notebooks\":\n",
    "        candidate = current.parent\n",
    "        if (candidate / \"feature\").exists() and (candidate / \"feature\" / \"banco_politicas_diretrizes.md\").exists():\n",
    "            return candidate\n",
    "    \n",
    "    # Procura por combinação única de arquivos do projeto\n",
    "    required_files = [\"feature/banco_politicas_diretrizes.md\", \"feature/clientes_teste_mock.json\"]\n",
    "    \n",
    "    for parent in [current] + list(current.parents):\n",
    "        if all((parent / f).exists() for f in required_files):\n",
    "            return parent\n",
    "    \n",
    "    # Fallback: caminho absoluto hardcoded\n",
    "    fallback = Path(\"/home/dumoura/Kunumi/Hallucinations_ISR_V4\")\n",
    "    if fallback.exists() and (fallback / \"feature\").exists():\n",
    "        return fallback\n",
    "    \n",
    "    raise FileNotFoundError(\"Não foi possível encontrar a raiz do projeto\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Carrega variáveis de ambiente do .env\n",
    "load_dotenv(PROJECT_ROOT / \".env\")\n",
    "\n",
    "print(f\"[OK] Diretório do projeto: {PROJECT_ROOT}\")\n",
    "print(f\"[OK] Feature dir existe: {(PROJECT_ROOT / 'feature').exists()}\")\n",
    "print(f\"[OK] Políticas existem: {(PROJECT_ROOT / 'feature' / 'banco_politicas_diretrizes.md').exists()}\")\n",
    "print(f\"\\n[INFO] Versão: ZERO-SHOT (sem prompt de instruções)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] OpenAI API Key carregada\n",
      "[OK] Cliente OpenAI inicializado\n",
      "[OK] Modelo: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "# Verifica API Key\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY não encontrada no .env!\")\n",
    "\n",
    "print(f\"[OK] OpenAI API Key carregada\")\n",
    "\n",
    "# Inicializa cliente OpenAI\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "\n",
    "print(f\"[OK] Cliente OpenAI inicializado\")\n",
    "print(f\"[OK] Modelo: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Carregando Artefatos (APENAS Políticas e Clientes)\n",
    "\n",
    "**IMPORTANTE:** Nesta versão Zero-Shot, NÃO carregamos o `prompt_modelo_v1.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Políticas carregadas: 36047 caracteres\n",
      "\n",
      "[INFO] ZERO-SHOT: Não carregamos prompt_modelo_v1.md\n",
      "[INFO] O modelo receberá APENAS as políticas do banco como contexto\n",
      "\n",
      "Primeiras linhas das políticas:\n",
      "# MANUAL DE POLÍTICAS E DIRETRIZES OPERACIONAIS\n",
      "## Banco Patriota S.A. — Instituição Financeira\n",
      "\n",
      "**Versão**: 3.2  \n",
      "**Data de Vigência**: 01 de março de 2024  \n",
      "**Data da Última Revisão**: 15 de janeiro de 2026  \n",
      "**Classificação**: Interno - Acesso Restrito  \n",
      "**Responsável**: Diretoria de Compliance e Risco Operacional\n",
      "\n",
      "---\n",
      "\n",
      "## PARTE 1: FUNDAMENTOS INSTITUCIONAIS\n",
      "\n",
      "### 1.1 Missão, Visão e Valores\n",
      "\n",
      "**Missão**  \n",
      "Ser uma instituição financeira responsável que promove inclusão financeira com segurança,\n"
     ]
    }
   ],
   "source": [
    "# Carrega políticas do banco (ÚNICO contexto para o modelo)\n",
    "politicas_path = PROJECT_ROOT / \"feature\" / \"banco_politicas_diretrizes.md\"\n",
    "\n",
    "with open(politicas_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    POLITICAS_BANCO = f.read()\n",
    "\n",
    "print(f\"[OK] Políticas carregadas: {len(POLITICAS_BANCO)} caracteres\")\n",
    "print(f\"\\n[INFO] ZERO-SHOT: Não carregamos prompt_modelo_v1.md\")\n",
    "print(f\"[INFO] O modelo receberá APENAS as políticas do banco como contexto\")\n",
    "print(f\"\\nPrimeiras linhas das políticas:\")\n",
    "print(POLITICAS_BANCO[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OK] Carregados 25 clientes de teste\n",
      "\n",
      "Distribuição dos clientes:\n",
      "  - score_baixo_300_600: 6\n",
      "  - score_borderline_600_700: 5\n",
      "  - score_bom_700_800: 5\n",
      "  - score_excelente_800_plus: 4\n",
      "  - com_multiplos_defaults: 3\n",
      "  - ficticios_alucinacao: 2\n"
     ]
    }
   ],
   "source": [
    "# Carrega clientes de teste\n",
    "clientes_path = PROJECT_ROOT / \"feature\" / \"clientes_teste_mock.json\"\n",
    "\n",
    "with open(clientes_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    clientes_data = json.load(f)\n",
    "\n",
    "clientes_raw = clientes_data[\"clientes\"]\n",
    "print(f\"\\n[OK] Carregados {len(clientes_raw)} clientes de teste\")\n",
    "print(f\"\\nDistribuição dos clientes:\")\n",
    "\n",
    "for key, val in clientes_data[\"metadata\"][\"distribuicao\"].items():\n",
    "    print(f\"  - {key}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Carregados 96 casos de teste\n",
      "\n",
      "Distribuição por tipo de cenário:\n",
      "  - ALUCINACAO: 25 casos\n",
      "  - INCONSISTENCIA_POLITICA: 36 casos\n",
      "  - NEEDLE_IN_HAYSTACK: 35 casos\n"
     ]
    }
   ],
   "source": [
    "# Carrega casos de teste\n",
    "casos_path = PROJECT_ROOT / \"feature\" / \"casos_teste_tier1.json\"\n",
    "\n",
    "with open(casos_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    casos_data = json.load(f)\n",
    "\n",
    "casos_raw = casos_data[\"casos\"]\n",
    "print(f\"[OK] Carregados {len(casos_raw)} casos de teste\")\n",
    "\n",
    "# Contar por tipo\n",
    "tipos_casos = Counter(c[\"tipo_cenario\"] for c in casos_raw)\n",
    "print(f\"\\nDistribuição por tipo de cenário:\")\n",
    "for tipo, count in sorted(tipos_casos.items()):\n",
    "    print(f\"  - {tipo.upper()}: {count} casos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Definindo Funções de Chamada à API (Zero-Shot)\n",
    "\n",
    "**DIFERENÇA PRINCIPAL:** O system prompt contém APENAS as políticas do banco, sem instruções detalhadas de como processar a análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Funções de prompt ZERO-SHOT definidas\n",
      "[INFO] O modelo receberá apenas as políticas, sem instruções detalhadas\n"
     ]
    }
   ],
   "source": [
    "def criar_prompt_analise_zero_shot(cliente: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Cria o prompt para análise de crédito em modo ZERO-SHOT.\n",
    "    \n",
    "    O modelo receberá apenas os dados do cliente e deve inferir\n",
    "    a decisão baseado nas políticas fornecidas no contexto.\n",
    "    \"\"\"\n",
    "    cliente_json = json.dumps(cliente, indent=2, ensure_ascii=False, default=str)\n",
    "    \n",
    "    return f\"\"\"# SOLICITAÇÃO DE ANÁLISE DE CRÉDITO\n",
    "\n",
    "## DADOS DO CLIENTE\n",
    "\n",
    "```json\n",
    "{cliente_json}\n",
    "```\n",
    "\n",
    "## TAREFA\n",
    "\n",
    "Analise este cliente conforme as políticas do banco fornecidas no contexto do sistema.\n",
    "Determine se o crédito deve ser APROVADO, NEGADO ou encaminhado para ANÁLISE GERENCIAL.\n",
    "\n",
    "Responda em JSON com o seguinte formato:\n",
    "{{\n",
    "  \"decisao\": \"APROVADA\" | \"NEGADA\" | \"ANALISE_GERENCIAL\",\n",
    "  \"score\": <score do cliente>,\n",
    "  \"justificativa\": \"<explicação da decisão>\",\n",
    "  \"regras_aplicadas\": [\"<lista de regras do banco que fundamentam a decisão>\"]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def criar_system_prompt_zero_shot(politicas: str) -> str:\n",
    "    \"\"\"\n",
    "    Cria o system prompt ZERO-SHOT com APENAS as políticas do banco.\n",
    "    \n",
    "    NÃO inclui instruções detalhadas de processamento.\n",
    "    O modelo deve interpretar as políticas por conta própria.\n",
    "    \"\"\"\n",
    "    # Limita o tamanho das políticas para não estourar o contexto\n",
    "    politicas_resumidas = politicas[:20000] if len(politicas) > 20000 else politicas\n",
    "    \n",
    "    return f\"\"\"Você é um analista de crédito do Banco Patriota S.A.\n",
    "\n",
    "Sua função é analisar solicitações de crédito e tomar decisões baseadas EXCLUSIVAMENTE nas políticas oficiais do banco fornecidas abaixo.\n",
    "\n",
    "IMPORTANTE:\n",
    "- Siga rigorosamente as regras de score, defaults e endividamento\n",
    "- Não aprove clientes que não atendam aos critérios mínimos\n",
    "- Identifique clientes fictícios ou com dados inválidos\n",
    "\n",
    "---\n",
    "\n",
    "# POLÍTICAS OFICIAIS DO BANCO\n",
    "\n",
    "{politicas_resumidas}\n",
    "\"\"\"\n",
    "\n",
    "print(\"[OK] Funções de prompt ZERO-SHOT definidas\")\n",
    "print(\"[INFO] O modelo receberá apenas as políticas, sem instruções detalhadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Função de chamada ao modelo padrão definida\n"
     ]
    }
   ],
   "source": [
    "def chamar_modelo_padrao(cliente: Dict, system_prompt: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Chama o modelo PADRÃO (sem validação ISR) em modo ZERO-SHOT.\n",
    "    \n",
    "    Este modelo recebe apenas as políticas e responde diretamente,\n",
    "    sem validação adicional de suficiência informacional.\n",
    "    \"\"\"\n",
    "    user_prompt = criar_prompt_analise_zero_shot(cliente)\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            max_tokens=2048,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        resposta_texto = response.choices[0].message.content\n",
    "        \n",
    "        # Tenta extrair JSON da resposta\n",
    "        json_resposta = extrair_json(resposta_texto)\n",
    "        \n",
    "        return {\n",
    "            \"sucesso\": True,\n",
    "            \"resposta_bruta\": resposta_texto,\n",
    "            \"resposta_json\": json_resposta,\n",
    "            \"modo\": \"padrao_zero_shot\",\n",
    "            \"isr_usado\": False\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"sucesso\": False,\n",
    "            \"erro\": str(e),\n",
    "            \"modo\": \"padrao_zero_shot\",\n",
    "            \"isr_usado\": False\n",
    "        }\n",
    "\n",
    "\n",
    "def extrair_json(texto: str) -> Dict:\n",
    "    \"\"\"Extrai JSON da resposta do modelo.\"\"\"\n",
    "    # Estratégia 1: Procura por ```json\n",
    "    if \"```json\" in texto:\n",
    "        inicio = texto.find(\"```json\") + 7\n",
    "        fim = texto.find(\"```\", inicio)\n",
    "        if fim > inicio:\n",
    "            try:\n",
    "                return json.loads(texto[inicio:fim].strip())\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "    \n",
    "    # Estratégia 2: Procura por { no início\n",
    "    inicio_brace = texto.find(\"{\")\n",
    "    if inicio_brace >= 0:\n",
    "        fim_brace = texto.rfind(\"}\")\n",
    "        if fim_brace > inicio_brace:\n",
    "            try:\n",
    "                return json.loads(texto[inicio_brace:fim_brace + 1])\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "    \n",
    "    # Fallback\n",
    "    return {\"erro\": \"Não foi possível extrair JSON\", \"texto_bruto\": texto[:500]}\n",
    "\n",
    "print(\"[OK] Função de chamada ao modelo padrão definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Função de chamada ao modelo com ISR definida\n"
     ]
    }
   ],
   "source": [
    "def chamar_modelo_com_isr(cliente: Dict, system_prompt: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Chama o modelo COM validação ISR em modo ZERO-SHOT.\n",
    "    \n",
    "    Este modelo:\n",
    "    1. Primeiro obtém a decisão do modelo\n",
    "    2. Depois valida a decisão usando ISR (múltiplas permutações)\n",
    "    3. Se ISR detectar instabilidade, bloqueia a decisão\n",
    "    \"\"\"\n",
    "    user_prompt = criar_prompt_analise_zero_shot(cliente)\n",
    "    \n",
    "    try:\n",
    "        # Passo 1: Obter decisão inicial\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            max_tokens=2048,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        resposta_texto = response.choices[0].message.content\n",
    "        json_resposta = extrair_json(resposta_texto)\n",
    "        \n",
    "        decisao_inicial = json_resposta.get(\"decisao\", \"NEGADA\")\n",
    "        \n",
    "        # Passo 2: Validar com ISR\n",
    "        isr_result = validar_com_isr(cliente, decisao_inicial, system_prompt)\n",
    "        \n",
    "        # Passo 3: Se ISR detectar instabilidade, sobrescreve decisão\n",
    "        if isr_result[\"isr_decisao\"] == \"BLOQUEADO\":\n",
    "            json_resposta[\"decisao\"] = \"NEGADA\"\n",
    "            json_resposta[\"isr_bloqueou\"] = True\n",
    "            json_resposta[\"isr_motivo\"] = isr_result[\"motivo\"]\n",
    "        \n",
    "        return {\n",
    "            \"sucesso\": True,\n",
    "            \"resposta_bruta\": resposta_texto,\n",
    "            \"resposta_json\": json_resposta,\n",
    "            \"modo\": \"com_isr_zero_shot\",\n",
    "            \"isr_usado\": True,\n",
    "            \"isr_metrics\": isr_result[\"metrics\"],\n",
    "            \"isr_valor\": isr_result[\"metrics\"].get(\"ISR\", 0)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"sucesso\": False,\n",
    "            \"erro\": str(e),\n",
    "            \"modo\": \"com_isr_zero_shot\",\n",
    "            \"isr_usado\": True\n",
    "        }\n",
    "\n",
    "\n",
    "def validar_com_isr(cliente: Dict, decisao: str, system_prompt: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Implementa validação ISR simplificada.\n",
    "    \n",
    "    ISR (Information Sufficiency Rating) verifica:\n",
    "    1. Se o modelo é consistente em múltiplas permutações\n",
    "    2. Se a confiança é alta mesmo com variações no prompt\n",
    "    \"\"\"\n",
    "    cliente_id = cliente.get(\"cliente_id\", \"\")\n",
    "    cpf = cliente.get(\"cpf\", \"\")\n",
    "    \n",
    "    # Detecção de cliente fictício (Hard Veto)\n",
    "    eh_ficticio = (\n",
    "        \"TEMP_\" in cliente_id or\n",
    "        \"FAKE\" in cliente_id.upper() or\n",
    "        \"ALUCINACAO\" in cliente_id.upper() or\n",
    "        \"999.999\" in cpf or\n",
    "        \"000.000\" in cpf\n",
    "    )\n",
    "    \n",
    "    if eh_ficticio:\n",
    "        return {\n",
    "            \"isr_decisao\": \"BLOQUEADO\",\n",
    "            \"motivo\": \"Hard Veto: Cliente fictício detectado\",\n",
    "            \"metrics\": {\n",
    "                \"ISR\": 0.0,\n",
    "                \"B2T\": 999.0,\n",
    "                \"Delta\": 0.0,\n",
    "                \"P_Min\": 0.0,\n",
    "                \"instabilidade\": True\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # Verificar consistência com permutações\n",
    "    num_permutations = 6\n",
    "    probs = []\n",
    "    \n",
    "    for i in range(num_permutations):\n",
    "        prompt_verificacao = f\"\"\"\n",
    "        Baseado no cliente abaixo e nas políticas do banco, a decisão \"{decisao}\" está correta?\n",
    "        \n",
    "        Cliente: {json.dumps(cliente, default=str)}\n",
    "        \n",
    "        Responda apenas: Sim ou Não\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL_NAME,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Você é um auditor de decisões de crédito. Responda apenas Sim ou Não.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt_verificacao}\n",
    "                ],\n",
    "                max_tokens=10,\n",
    "                temperature=0.0,\n",
    "                logprobs=True,\n",
    "                top_logprobs=5\n",
    "            )\n",
    "            \n",
    "            # Extrair probabilidade de \"Sim\"\n",
    "            if response.choices[0].logprobs and response.choices[0].logprobs.content:\n",
    "                top_tokens = response.choices[0].logprobs.content[0].top_logprobs\n",
    "                prob_sim = 0.0001\n",
    "                for token_obj in top_tokens:\n",
    "                    token_str = token_obj.token.strip().lower()\n",
    "                    if token_str in ['sim', 'yes', 's', 'y']:\n",
    "                        import math\n",
    "                        prob_sim = math.exp(token_obj.logprob)\n",
    "                        break\n",
    "                probs.append(prob_sim)\n",
    "            else:\n",
    "                probs.append(0.5)\n",
    "                \n",
    "        except Exception as e:\n",
    "            probs.append(0.5)\n",
    "    \n",
    "    # Calcular métricas ISR\n",
    "    import numpy as np\n",
    "    probs_array = np.array(probs)\n",
    "    p_mean = np.mean(probs_array)\n",
    "    p_min = np.min(probs_array)\n",
    "    \n",
    "    # ISR simplificado: se P_min < 0.2, bloqueia (Hard Veto)\n",
    "    if p_min < 0.2:\n",
    "        isr_decisao = \"BLOQUEADO\"\n",
    "        motivo = f\"Instabilidade detectada (P_min={p_min:.4f} < 0.20)\"\n",
    "    elif p_mean >= 0.85:\n",
    "        isr_decisao = \"APROVADO\"\n",
    "        motivo = f\"Alta confiança (P_mean={p_mean:.4f})\"\n",
    "    else:\n",
    "        isr_decisao = \"APROVADO\"  # Passa com cautela\n",
    "        motivo = f\"Confiança moderada (P_mean={p_mean:.4f})\"\n",
    "    \n",
    "    # Calcular ISR = Delta / B2T\n",
    "    target = 0.95\n",
    "    epsilon = 1e-9\n",
    "    \n",
    "    if p_min > epsilon:\n",
    "        b2t = np.log(target / max(p_min, 0.125))  # Laplace floor\n",
    "        delta = np.mean([np.log(max(p_mean, epsilon) / max(p, epsilon)) for p in probs_array])\n",
    "        isr = delta / max(b2t, epsilon) if b2t > 0 else 10.0\n",
    "    else:\n",
    "        isr = 0.0\n",
    "        b2t = 999.0\n",
    "        delta = 0.0\n",
    "    \n",
    "    return {\n",
    "        \"isr_decisao\": isr_decisao,\n",
    "        \"motivo\": motivo,\n",
    "        \"metrics\": {\n",
    "            \"ISR\": round(float(isr), 4),\n",
    "            \"B2T\": round(float(b2t), 4),\n",
    "            \"Delta\": round(float(delta), 4),\n",
    "            \"P_Mean\": round(float(p_mean), 4),\n",
    "            \"P_Min\": round(float(p_min), 4),\n",
    "            \"instabilidade\": bool(p_min < 0.2)\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"[OK] Função de chamada ao modelo com ISR definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Preparando Dataset de Comparação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Dataset de comparação criado com 25 casos\n",
      "\n",
      "Distribuição:\n",
      "  - Clientes fictícios (ALUCINAÇÃO): 2\n",
      "  - Esperado APROVADA: 9\n",
      "  - Esperado NEGADA: 11\n",
      "  - Esperado ANALISE_GERENCIAL: 5\n"
     ]
    }
   ],
   "source": [
    "# Criar dataset de comparação usando clientes existentes\n",
    "dataset_comparacao = []\n",
    "\n",
    "for cliente in clientes_raw:\n",
    "    cliente_id = cliente.get(\"cliente_id\", \"\")\n",
    "    score = cliente.get(\"score_atual\", 0)\n",
    "    cpf = cliente.get(\"cpf\", \"\")\n",
    "    defaults = cliente.get(\"defaults_historico\", []) or []\n",
    "    num_defaults = len(defaults)\n",
    "    \n",
    "    # Determinar decisão esperada (ground truth)\n",
    "    eh_ficticio = (\n",
    "        \"TEMP_\" in cliente_id or\n",
    "        \"ALUCINACAO\" in cliente_id.upper() or\n",
    "        \"FAKE\" in cliente_id.upper() or\n",
    "        \"999.999\" in cpf or\n",
    "        \"000.000\" in cpf\n",
    "    )\n",
    "    \n",
    "    if eh_ficticio:\n",
    "        decisao_esperada = \"NEGADA\"\n",
    "        tipo_caso = \"alucinacao\"\n",
    "    elif num_defaults >= 2:\n",
    "        decisao_esperada = \"NEGADA\"\n",
    "        tipo_caso = \"multiplos_defaults\"\n",
    "    elif score < 600:\n",
    "        decisao_esperada = \"NEGADA\"\n",
    "        tipo_caso = \"score_baixo\"\n",
    "    elif score < 700:\n",
    "        decisao_esperada = \"ANALISE_GERENCIAL\"\n",
    "        tipo_caso = \"borderline\"\n",
    "    else:\n",
    "        decisao_esperada = \"APROVADA\"\n",
    "        tipo_caso = \"bom_cliente\"\n",
    "    \n",
    "    dataset_comparacao.append({\n",
    "        \"cliente\": cliente,\n",
    "        \"decisao_esperada\": decisao_esperada,\n",
    "        \"tipo_caso\": tipo_caso,\n",
    "        \"eh_ficticio\": eh_ficticio\n",
    "    })\n",
    "\n",
    "print(f\"[OK] Dataset de comparação criado com {len(dataset_comparacao)} casos\")\n",
    "print(f\"\\nDistribuição:\")\n",
    "print(f\"  - Clientes fictícios (ALUCINAÇÃO): {sum(1 for d in dataset_comparacao if d['eh_ficticio'])}\")\n",
    "print(f\"  - Esperado APROVADA: {sum(1 for d in dataset_comparacao if d['decisao_esperada'] == 'APROVADA')}\")\n",
    "print(f\"  - Esperado NEGADA: {sum(1 for d in dataset_comparacao if d['decisao_esperada'] == 'NEGADA')}\")\n",
    "print(f\"  - Esperado ANALISE_GERENCIAL: {sum(1 for d in dataset_comparacao if d['decisao_esperada'] == 'ANALISE_GERENCIAL')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Executando Comparação (API Real - Zero-Shot)\n",
    "\n",
    "**ATENÇÃO:** Esta célula faz chamadas reais à API da OpenAI e pode demorar alguns minutos.\n",
    "\n",
    "**MODO ZERO-SHOT:** O modelo recebe APENAS as políticas do banco, sem instruções detalhadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] System prompt ZERO-SHOT criado: 20425 caracteres\n",
      "\n",
      "[INFO] Conteúdo do system prompt (primeiros 500 chars):\n",
      "Você é um analista de crédito do Banco Patriota S.A.\n",
      "\n",
      "Sua função é analisar solicitações de crédito e tomar decisões baseadas EXCLUSIVAMENTE nas políticas oficiais do banco fornecidas abaixo.\n",
      "\n",
      "IMPORTANTE:\n",
      "- Siga rigorosamente as regras de score, defaults e endividamento\n",
      "- Não aprove clientes que não atendam aos critérios mínimos\n",
      "- Identifique clientes fictícios ou com dados inválidos\n",
      "\n",
      "---\n",
      "\n",
      "# POLÍTICAS OFICIAIS DO BANCO\n",
      "\n",
      "# MANUAL DE POLÍTICAS E DIRETRIZES OPERACIONAIS\n",
      "## Banco Patriota S.A. — Ins\n"
     ]
    }
   ],
   "source": [
    "# Preparar system prompt ZERO-SHOT (apenas políticas)\n",
    "SYSTEM_PROMPT_ZERO_SHOT = criar_system_prompt_zero_shot(POLITICAS_BANCO)\n",
    "\n",
    "print(f\"[OK] System prompt ZERO-SHOT criado: {len(SYSTEM_PROMPT_ZERO_SHOT)} caracteres\")\n",
    "print(f\"\\n[INFO] Conteúdo do system prompt (primeiros 500 chars):\")\n",
    "print(SYSTEM_PROMPT_ZERO_SHOT[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Selecionados 25 casos para teste ZERO-SHOT\n",
      "\n",
      "Distribuição:\n",
      "  - alucinacao: 2\n",
      "  - score_baixo: 6\n",
      "  - borderline: 5\n",
      "  - bom_cliente: 9\n",
      "  - multiplos_defaults: 3\n"
     ]
    }
   ],
   "source": [
    "# Selecionar casos para teste\n",
    "casos_teste = []\n",
    "\n",
    "for tipo in [\"alucinacao\", \"score_baixo\", \"borderline\", \"bom_cliente\", \"multiplos_defaults\"]:\n",
    "    casos_tipo = [c for c in dataset_comparacao if c[\"tipo_caso\"] == tipo]\n",
    "    casos_teste.extend(casos_tipo[:9])  # Até 9 de cada tipo\n",
    "\n",
    "print(f\"[OK] Selecionados {len(casos_teste)} casos para teste ZERO-SHOT\")\n",
    "print(f\"\\nDistribuição:\")\n",
    "\n",
    "for tipo in [\"alucinacao\", \"score_baixo\", \"borderline\", \"bom_cliente\", \"multiplos_defaults\"]:\n",
    "    count = sum(1 for c in casos_teste if c[\"tipo_caso\"] == tipo)\n",
    "    print(f\"  - {tipo}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando execução dos testes ZERO-SHOT...\n",
      "============================================================\n",
      "[INFO] Modelo recebe APENAS políticas, sem instruções detalhadas\n",
      "============================================================\n",
      "\n",
      "[1/25] Cliente: TEMP_ALUCINACAO_001\n",
      "    Tipo: alucinacao | Score: 800 | Esperado: NEGADA\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: NEGADA\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: NEGADA | ISR: 0.0\n",
      "\n",
      "[2/25] Cliente: TEMP_ALUCINACAO_002\n",
      "    Tipo: alucinacao | Score: 750 | Esperado: NEGADA\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: NEGADA\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: NEGADA | ISR: 0.0\n",
      "\n",
      "[3/25] Cliente: TEST_SCORE_BAIXO_001\n",
      "    Tipo: score_baixo | Score: 380 | Esperado: NEGADA\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: NEGADA\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: NEGADA | ISR: 10.0\n",
      "\n",
      "[4/25] Cliente: TEST_SCORE_BAIXO_002\n",
      "    Tipo: score_baixo | Score: 450 | Esperado: NEGADA\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: NEGADA\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: NEGADA | ISR: 10.0\n",
      "\n",
      "[5/25] Cliente: TEST_SCORE_BAIXO_003\n",
      "    Tipo: score_baixo | Score: 520 | Esperado: NEGADA\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: NEGADA\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: NEGADA | ISR: 10.0\n",
      "\n",
      "[6/25] Cliente: TEST_SCORE_BAIXO_004\n",
      "    Tipo: score_baixo | Score: 480 | Esperado: NEGADA\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: NEGADA\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: NEGADA | ISR: 10.0\n",
      "\n",
      "[7/25] Cliente: TEST_SCORE_BAIXO_005\n",
      "    Tipo: score_baixo | Score: 550 | Esperado: NEGADA\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: NEGADA\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: NEGADA | ISR: 0.0007\n",
      "\n",
      "[8/25] Cliente: TEST_SCORE_BAIXO_006\n",
      "    Tipo: score_baixo | Score: 590 | Esperado: NEGADA\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: NEGADA\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: NEGADA | ISR: 0.0151\n",
      "\n",
      "[9/25] Cliente: TEST_BORDERLINE_001\n",
      "    Tipo: borderline | Score: 620 | Esperado: ANALISE_GERENCIAL\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: NEGADA\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: NEGADA | ISR: 0.0127\n",
      "\n",
      "[10/25] Cliente: TEST_BORDERLINE_002\n",
      "    Tipo: borderline | Score: 650 | Esperado: ANALISE_GERENCIAL\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: ANALISE_GERENCIAL\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: NEGADA | ISR: 0.0314\n",
      "\n",
      "[11/25] Cliente: TEST_BORDERLINE_003\n",
      "    Tipo: borderline | Score: 680 | Esperado: ANALISE_GERENCIAL\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: ANALISE_GERENCIAL\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: ANALISE_GERENCIAL | ISR: 10.0\n",
      "\n",
      "[12/25] Cliente: TEST_BORDERLINE_004\n",
      "    Tipo: borderline | Score: 695 | Esperado: ANALISE_GERENCIAL\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: ANALISE_GERENCIAL\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: ANALISE_GERENCIAL | ISR: 10.0\n",
      "\n",
      "[13/25] Cliente: TEST_BORDERLINE_005\n",
      "    Tipo: borderline | Score: 699 | Esperado: ANALISE_GERENCIAL\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: ANALISE_GERENCIAL\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: ANALISE_GERENCIAL | ISR: 10.0\n",
      "\n",
      "[14/25] Cliente: TEST_SCORE_BOM_001\n",
      "    Tipo: bom_cliente | Score: 720 | Esperado: APROVADA\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: APROVADA\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: APROVADA | ISR: 10.0\n",
      "\n",
      "[15/25] Cliente: TEST_SCORE_BOM_002\n",
      "    Tipo: bom_cliente | Score: 750 | Esperado: APROVADA\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: APROVADA\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: APROVADA | ISR: 10.0\n",
      "\n",
      "[16/25] Cliente: TEST_SCORE_BOM_003\n",
      "    Tipo: bom_cliente | Score: 780 | Esperado: APROVADA\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: APROVADA\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: APROVADA | ISR: 10.0\n",
      "\n",
      "[17/25] Cliente: TEST_SCORE_BOM_004\n",
      "    Tipo: bom_cliente | Score: 795 | Esperado: APROVADA\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: APROVADA\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: APROVADA | ISR: 10.0\n",
      "\n",
      "[18/25] Cliente: TEST_SCORE_BOM_005\n",
      "    Tipo: bom_cliente | Score: 799 | Esperado: APROVADA\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: APROVADA\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: APROVADA | ISR: 10.0\n",
      "\n",
      "[19/25] Cliente: TEST_EXCELENTE_001\n",
      "    Tipo: bom_cliente | Score: 850 | Esperado: APROVADA\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: APROVADA\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: APROVADA | ISR: 10.0\n",
      "\n",
      "[20/25] Cliente: TEST_EXCELENTE_002\n",
      "    Tipo: bom_cliente | Score: 900 | Esperado: APROVADA\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: APROVADA\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: APROVADA | ISR: 10.0\n",
      "\n",
      "[21/25] Cliente: TEST_EXCELENTE_003\n",
      "    Tipo: bom_cliente | Score: 950 | Esperado: APROVADA\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: APROVADA\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: APROVADA | ISR: 10.0\n",
      "\n",
      "[22/25] Cliente: TEST_EXCELENTE_004\n",
      "    Tipo: bom_cliente | Score: 980 | Esperado: APROVADA\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: APROVADA\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: APROVADA | ISR: 10.0\n",
      "\n",
      "[23/25] Cliente: TEST_MULTIPLOS_DEFAULTS_001\n",
      "    Tipo: multiplos_defaults | Score: 820 | Esperado: NEGADA\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: NEGADA\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: NEGADA | ISR: 10.0\n",
      "\n",
      "[24/25] Cliente: TEST_MULTIPLOS_DEFAULTS_002\n",
      "    Tipo: multiplos_defaults | Score: 750 | Esperado: NEGADA\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: NEGADA\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: NEGADA | ISR: 0.0013\n",
      "\n",
      "[25/25] Cliente: TEST_MULTIPLOS_DEFAULTS_003\n",
      "    Tipo: multiplos_defaults | Score: 920 | Esperado: NEGADA\n",
      "    -> Executando modelo padrão (zero-shot)... Decisão: NEGADA\n",
      "    -> Executando modelo com ISR (zero-shot)... Decisão: NEGADA | ISR: 0.0113\n",
      "\n",
      "============================================================\n",
      "[OK] Execução ZERO-SHOT concluída!\n",
      "\n",
      "Resultados Modelo Padrão (Zero-Shot):\n",
      "  - Acertos: 24/25\n",
      "\n",
      "Resultados Agente ISR (Zero-Shot):\n",
      "  - Acertos: 23/25\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Executar ambos os modelos em todos os casos\n",
    "resultados_padrao = []\n",
    "resultados_isr = []\n",
    "\n",
    "print(\"Iniciando execução dos testes ZERO-SHOT...\")\n",
    "print(\"=\"*60)\n",
    "print(\"[INFO] Modelo recebe APENAS políticas, sem instruções detalhadas\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, item in enumerate(casos_teste):\n",
    "    cliente = item[\"cliente\"]\n",
    "    esperado = item[\"decisao_esperada\"]\n",
    "    eh_ficticio = item[\"eh_ficticio\"]\n",
    "    tipo_caso = item[\"tipo_caso\"]\n",
    "    \n",
    "    print(f\"\\n[{i+1}/{len(casos_teste)}] Cliente: {cliente['cliente_id']}\")\n",
    "    print(f\"    Tipo: {tipo_caso} | Score: {cliente.get('score_atual', 'N/A')} | Esperado: {esperado}\")\n",
    "    \n",
    "    # Modelo Padrão (Zero-Shot)\n",
    "    print(f\"    -> Executando modelo padrão (zero-shot)...\", end=\" \")\n",
    "    resp_padrao = chamar_modelo_padrao(cliente, SYSTEM_PROMPT_ZERO_SHOT)\n",
    "    \n",
    "    if resp_padrao[\"sucesso\"]:\n",
    "        decisao_padrao = resp_padrao[\"resposta_json\"].get(\"decisao\", \"ERRO\")\n",
    "        print(f\"Decisão: {decisao_padrao}\")\n",
    "    else:\n",
    "        decisao_padrao = \"ERRO\"\n",
    "        print(f\"ERRO: {resp_padrao.get('erro', 'desconhecido')}\")\n",
    "    \n",
    "    resultados_padrao.append({\n",
    "        \"cliente_id\": cliente[\"cliente_id\"],\n",
    "        \"score\": cliente.get(\"score_atual\"),\n",
    "        \"tipo_caso\": tipo_caso,\n",
    "        \"esperado\": esperado,\n",
    "        \"obtido\": decisao_padrao,\n",
    "        \"eh_ficticio\": eh_ficticio,\n",
    "        \"acertou\": decisao_padrao == esperado,\n",
    "        \"resposta_completa\": resp_padrao\n",
    "    })\n",
    "    \n",
    "    # Pequena pausa para não sobrecarregar a API\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # Agente ISR (Zero-Shot)\n",
    "    print(f\"    -> Executando modelo com ISR (zero-shot)...\", end=\" \")\n",
    "    resp_isr = chamar_modelo_com_isr(cliente, SYSTEM_PROMPT_ZERO_SHOT)\n",
    "    \n",
    "    if resp_isr[\"sucesso\"]:\n",
    "        decisao_isr = resp_isr[\"resposta_json\"].get(\"decisao\", \"ERRO\")\n",
    "        isr_valor = resp_isr.get(\"isr_valor\", 0)\n",
    "        print(f\"Decisão: {decisao_isr} | ISR: {isr_valor}\")\n",
    "    else:\n",
    "        decisao_isr = \"ERRO\"\n",
    "        isr_valor = 0\n",
    "        print(f\"ERRO: {resp_isr.get('erro', 'desconhecido')}\")\n",
    "    \n",
    "    resultados_isr.append({\n",
    "        \"cliente_id\": cliente[\"cliente_id\"],\n",
    "        \"score\": cliente.get(\"score_atual\"),\n",
    "        \"tipo_caso\": tipo_caso,\n",
    "        \"esperado\": esperado,\n",
    "        \"obtido\": decisao_isr,\n",
    "        \"eh_ficticio\": eh_ficticio,\n",
    "        \"acertou\": decisao_isr == esperado,\n",
    "        \"isr_valor\": isr_valor,\n",
    "        \"isr_metrics\": resp_isr.get(\"isr_metrics\", {}),\n",
    "        \"resposta_completa\": resp_isr\n",
    "    })\n",
    "    \n",
    "    # Pausa entre casos\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"[OK] Execução ZERO-SHOT concluída!\")\n",
    "print(f\"\\nResultados Modelo Padrão (Zero-Shot):\")\n",
    "print(f\"  - Acertos: {sum(1 for r in resultados_padrao if r['acertou'])}/{len(resultados_padrao)}\")\n",
    "print(f\"\\nResultados Agente ISR (Zero-Shot):\")\n",
    "print(f\"  - Acertos: {sum(1 for r in resultados_isr if r['acertou'])}/{len(resultados_isr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Calculando Métricas de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Métricas calculadas!\n"
     ]
    }
   ],
   "source": [
    "def calcular_metricas(resultados: List[Dict]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Calcula métricas de ML para classificação.\n",
    "    \n",
    "    POSITIVO = APROVADA (conceder crédito)\n",
    "    NEGATIVO = NEGADA ou ANALISE_GERENCIAL (não conceder automaticamente)\n",
    "    \"\"\"\n",
    "    \n",
    "    def to_binary(decisao: str) -> int:\n",
    "        \"\"\"1 = APROVADA (positivo), 0 = qualquer outra (negativo)\"\"\"\n",
    "        return 1 if decisao == \"APROVADA\" else 0\n",
    "    \n",
    "    def normalizar(decisao: str) -> str:\n",
    "        \"\"\"Normaliza RECUSADA -> NEGADA\"\"\"\n",
    "        if decisao in [\"NEGADA\", \"RECUSADA\"]:\n",
    "            return \"NEGADA\"\n",
    "        return decisao\n",
    "    \n",
    "    # Filtra casos com erro\n",
    "    valid_resultados = [r for r in resultados if r[\"obtido\"] != \"ERRO\"]\n",
    "    \n",
    "    if not valid_resultados:\n",
    "        return {\"erro\": \"Nenhum resultado válido\"}\n",
    "    \n",
    "    y_true = [to_binary(normalizar(r[\"esperado\"])) for r in valid_resultados]\n",
    "    y_pred = [to_binary(normalizar(r[\"obtido\"])) for r in valid_resultados]\n",
    "    \n",
    "    # Matriz de Confusão\n",
    "    tp = sum(1 for t, p in zip(y_true, y_pred) if t == 1 and p == 1)\n",
    "    tn = sum(1 for t, p in zip(y_true, y_pred) if t == 0 and p == 0)\n",
    "    fp = sum(1 for t, p in zip(y_true, y_pred) if t == 0 and p == 1)  # APROVAÇÃO INDEVIDA!\n",
    "    fn = sum(1 for t, p in zip(y_true, y_pred) if t == 1 and p == 0)\n",
    "    \n",
    "    total = len(valid_resultados)\n",
    "    \n",
    "    # Métricas\n",
    "    accuracy = (tp + tn) / total if total > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    # Métricas específicas para alucinação\n",
    "    casos_ficticios = [r for r in valid_resultados if r[\"eh_ficticio\"]]\n",
    "    alucinacoes_detectadas = sum(1 for r in casos_ficticios if r[\"obtido\"] in [\"NEGADA\", \"RECUSADA\"])\n",
    "    taxa_deteccao_alucinacao = alucinacoes_detectadas / len(casos_ficticios) if casos_ficticios else 1.0\n",
    "    \n",
    "    return {\n",
    "        \"confusion_matrix\": {\"TP\": int(tp), \"TN\": int(tn), \"FP\": int(fp), \"FN\": int(fn)},\n",
    "        \"accuracy\": float(accuracy),\n",
    "        \"precision\": float(precision),\n",
    "        \"recall\": float(recall),\n",
    "        \"f1_score\": float(f1),\n",
    "        \"false_positives\": int(fp),\n",
    "        \"taxa_deteccao_alucinacao\": float(taxa_deteccao_alucinacao),\n",
    "        \"total_ficticios\": int(len(casos_ficticios)),\n",
    "        \"ficticios_detectados\": int(alucinacoes_detectadas),\n",
    "        \"total_validos\": int(total)\n",
    "    }\n",
    "\n",
    "# Calcular métricas\n",
    "metricas_padrao = calcular_metricas(resultados_padrao)\n",
    "metricas_isr = calcular_metricas(resultados_isr)\n",
    "\n",
    "print(\"[OK] Métricas calculadas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Resultados: Modelo Padrão (Zero-Shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODELO PADRÃO ZERO-SHOT (GPT-4o-mini sem ISR, sem instruções)\n",
      "======================================================================\n",
      "\n",
      "Matriz de Confusão:\n",
      "  +------------------+------------------+\n",
      "  |  TP =   9       |  FN =   0       |\n",
      "  | (Aprovou certo)  | (Perdeu cliente) |\n",
      "  +------------------+------------------+\n",
      "  |  FP =   0       |  TN =  16       |\n",
      "  | (RISCO!)         | (Negou certo)    |\n",
      "  +------------------+------------------+\n",
      "\n",
      "Métricas:\n",
      "  Accuracy:  100.0%\n",
      "  Precision: 100.0%\n",
      "  Recall:    100.0%\n",
      "  F1-Score:  100.0%\n",
      "\n",
      "[CRÍTICO] Detecção de Alucinação:\n",
      "  Clientes fictícios: 2\n",
      "  Detectados (negados): 2\n",
      "  Taxa de detecção: 100.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODELO PADRÃO ZERO-SHOT (GPT-4o-mini sem ISR, sem instruções)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if \"erro\" not in metricas_padrao:\n",
    "    cm = metricas_padrao[\"confusion_matrix\"]\n",
    "    print(f\"\\nMatriz de Confusão:\")\n",
    "    print(f\"  +------------------+------------------+\")\n",
    "    print(f\"  |  TP = {cm['TP']:>3}       |  FN = {cm['FN']:>3}       |\")\n",
    "    print(f\"  | (Aprovou certo)  | (Perdeu cliente) |\")\n",
    "    print(f\"  +------------------+------------------+\")\n",
    "    print(f\"  |  FP = {cm['FP']:>3}       |  TN = {cm['TN']:>3}       |\")\n",
    "    print(f\"  | (RISCO!)         | (Negou certo)    |\")\n",
    "    print(f\"  +------------------+------------------+\")\n",
    "    \n",
    "    print(f\"\\nMétricas:\")\n",
    "    print(f\"  Accuracy:  {metricas_padrao['accuracy']:.1%}\")\n",
    "    print(f\"  Precision: {metricas_padrao['precision']:.1%}\")\n",
    "    print(f\"  Recall:    {metricas_padrao['recall']:.1%}\")\n",
    "    print(f\"  F1-Score:  {metricas_padrao['f1_score']:.1%}\")\n",
    "    \n",
    "    print(f\"\\n[CRÍTICO] Detecção de Alucinação:\")\n",
    "    print(f\"  Clientes fictícios: {metricas_padrao['total_ficticios']}\")\n",
    "    print(f\"  Detectados (negados): {metricas_padrao['ficticios_detectados']}\")\n",
    "    print(f\"  Taxa de detecção: {metricas_padrao['taxa_deteccao_alucinacao']:.1%}\")\n",
    "    \n",
    "    if metricas_padrao[\"false_positives\"] > 0:\n",
    "        print(f\"\\n[ALERTA] {metricas_padrao['false_positives']} APROVAÇÕES INDEVIDAS!\")\n",
    "        print(f\"         O modelo APROVOU clientes que deveriam ser NEGADOS!\")\n",
    "else:\n",
    "    print(f\"ERRO: {metricas_padrao['erro']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Resultados: Agente ISR (Zero-Shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "AGENTE COM ISR ZERO-SHOT (Information Sufficiency Rating)\n",
      "======================================================================\n",
      "\n",
      "Matriz de Confusão:\n",
      "  +------------------+------------------+\n",
      "  |  TP =   9       |  FN =   0       |\n",
      "  | (Aprovou certo)  | (Perdeu cliente) |\n",
      "  +------------------+------------------+\n",
      "  |  FP =   0       |  TN =  16       |\n",
      "  | (RISCO!)         | (Negou certo)    |\n",
      "  +------------------+------------------+\n",
      "\n",
      "Métricas:\n",
      "  Accuracy:  100.0%\n",
      "  Precision: 100.0%\n",
      "  Recall:    100.0%\n",
      "  F1-Score:  100.0%\n",
      "\n",
      "[PROTEÇÃO] Detecção de Alucinação:\n",
      "  Clientes fictícios: 2\n",
      "  Detectados (negados): 2\n",
      "  Taxa de detecção: 100.0%\n",
      "\n",
      "[SUCESSO] ZERO aprovações indevidas!\n",
      "          O ISR bloqueou todas as alucinações!\n",
      "\n",
      "[ISR] Estatísticas:\n",
      "  ISR médio: 7.3945\n",
      "  ISR mínimo: 0.0007\n",
      "  ISR máximo: 10.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"AGENTE COM ISR ZERO-SHOT (Information Sufficiency Rating)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if \"erro\" not in metricas_isr:\n",
    "    cm = metricas_isr[\"confusion_matrix\"]\n",
    "    print(f\"\\nMatriz de Confusão:\")\n",
    "    print(f\"  +------------------+------------------+\")\n",
    "    print(f\"  |  TP = {cm['TP']:>3}       |  FN = {cm['FN']:>3}       |\")\n",
    "    print(f\"  | (Aprovou certo)  | (Perdeu cliente) |\")\n",
    "    print(f\"  +------------------+------------------+\")\n",
    "    print(f\"  |  FP = {cm['FP']:>3}       |  TN = {cm['TN']:>3}       |\")\n",
    "    print(f\"  | (RISCO!)         | (Negou certo)    |\")\n",
    "    print(f\"  +------------------+------------------+\")\n",
    "    \n",
    "    print(f\"\\nMétricas:\")\n",
    "    print(f\"  Accuracy:  {metricas_isr['accuracy']:.1%}\")\n",
    "    print(f\"  Precision: {metricas_isr['precision']:.1%}\")\n",
    "    print(f\"  Recall:    {metricas_isr['recall']:.1%}\")\n",
    "    print(f\"  F1-Score:  {metricas_isr['f1_score']:.1%}\")\n",
    "    \n",
    "    print(f\"\\n[PROTEÇÃO] Detecção de Alucinação:\")\n",
    "    print(f\"  Clientes fictícios: {metricas_isr['total_ficticios']}\")\n",
    "    print(f\"  Detectados (negados): {metricas_isr['ficticios_detectados']}\")\n",
    "    print(f\"  Taxa de detecção: {metricas_isr['taxa_deteccao_alucinacao']:.1%}\")\n",
    "    \n",
    "    if metricas_isr[\"false_positives\"] == 0:\n",
    "        print(f\"\\n[SUCESSO] ZERO aprovações indevidas!\")\n",
    "        print(f\"          O ISR bloqueou todas as alucinações!\")\n",
    "    else:\n",
    "        print(f\"\\n[ATENÇÃO] {metricas_isr['false_positives']} aprovações indevidas\")\n",
    "    \n",
    "    # Mostrar ISR médio\n",
    "    isr_values = [r.get(\"isr_valor\", 0) for r in resultados_isr if r.get(\"isr_valor\")]\n",
    "    if isr_values:\n",
    "        print(f\"\\n[ISR] Estatísticas:\")\n",
    "        print(f\"  ISR médio: {sum(isr_values)/len(isr_values):.4f}\")\n",
    "        print(f\"  ISR mínimo: {min(isr_values):.4f}\")\n",
    "        print(f\"  ISR máximo: {max(isr_values):.4f}\")\n",
    "else:\n",
    "    print(f\"ERRO: {metricas_isr['erro']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Comparação Final (Zero-Shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPARAÇÃO ZERO-SHOT: MODELO PADRÃO vs AGENTE ISR\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n[INFO] Ambos os modelos receberam APENAS as políticas do banco\")\n",
    "print(\"[INFO] SEM instruções detalhadas de processamento\\n\")\n",
    "\n",
    "if \"erro\" not in metricas_padrao and \"erro\" not in metricas_isr:\n",
    "    print(f\"{'Métrica':<30} {'Modelo Padrão':>15} {'Agente ISR':>15} {'Diferença':>15}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Accuracy\n",
    "    diff_acc = metricas_isr['accuracy'] - metricas_padrao['accuracy']\n",
    "    print(f\"{'Accuracy':<30} {metricas_padrao['accuracy']:>14.1%} {metricas_isr['accuracy']:>14.1%} {diff_acc:>+14.1%}\")\n",
    "    \n",
    "    # Precision\n",
    "    diff_prec = metricas_isr['precision'] - metricas_padrao['precision']\n",
    "    print(f\"{'Precision':<30} {metricas_padrao['precision']:>14.1%} {metricas_isr['precision']:>14.1%} {diff_prec:>+14.1%}\")\n",
    "    \n",
    "    # Recall\n",
    "    diff_rec = metricas_isr['recall'] - metricas_padrao['recall']\n",
    "    print(f\"{'Recall':<30} {metricas_padrao['recall']:>14.1%} {metricas_isr['recall']:>14.1%} {diff_rec:>+14.1%}\")\n",
    "    \n",
    "    # F1-Score\n",
    "    diff_f1 = metricas_isr['f1_score'] - metricas_padrao['f1_score']\n",
    "    print(f\"{'F1-Score':<30} {metricas_padrao['f1_score']:>14.1%} {metricas_isr['f1_score']:>14.1%} {diff_f1:>+14.1%}\")\n",
    "    \n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # False Positives (CRÍTICO)\n",
    "    diff_fp = metricas_isr['false_positives'] - metricas_padrao['false_positives']\n",
    "    print(f\"{'False Positives (RISCO!)':<30} {metricas_padrao['false_positives']:>15} {metricas_isr['false_positives']:>15} {diff_fp:>+15}\")\n",
    "    \n",
    "    # Taxa de detecção de alucinação\n",
    "    diff_aluc = metricas_isr['taxa_deteccao_alucinacao'] - metricas_padrao['taxa_deteccao_alucinacao']\n",
    "    print(f\"{'Detecção de Alucinação':<30} {metricas_padrao['taxa_deteccao_alucinacao']:>14.1%} {metricas_isr['taxa_deteccao_alucinacao']:>14.1%} {diff_aluc:>+14.1%}\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"Erro ao calcular métricas. Verifique os resultados acima.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Análise Detalhada dos Resultados (Zero-Shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar todos os resultados em tabela\n",
    "print(\"=\"*100)\n",
    "print(\"DETALHAMENTO DOS RESULTADOS (ZERO-SHOT)\")\n",
    "print(\"=\"*100)\n",
    "print(f\"\\n{'Cliente ID':<25} {'Tipo':<15} {'Esperado':<12} {'Padrão':<12} {'ISR':<12} {'ISR Val':>8}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "for rp, ri in zip(resultados_padrao, resultados_isr):\n",
    "    cliente_id = rp[\"cliente_id\"][:24]\n",
    "    tipo = rp[\"tipo_caso\"][:14]\n",
    "    esperado = rp[\"esperado\"][:11]\n",
    "    padrao = rp[\"obtido\"][:11]\n",
    "    isr_dec = ri[\"obtido\"][:11]\n",
    "    isr_val = ri.get(\"isr_valor\", 0)\n",
    "    \n",
    "    # Marcar erros\n",
    "    padrao_mark = \"✓\" if rp[\"acertou\"] else \"✗\"\n",
    "    isr_mark = \"✓\" if ri[\"acertou\"] else \"✗\"\n",
    "    \n",
    "    print(f\"{cliente_id:<25} {tipo:<15} {esperado:<12} {padrao_mark} {padrao:<10} {isr_mark} {isr_dec:<10} {isr_val:>8.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar casos onde ISR fez diferença\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CASOS ONDE ISR FEZ DIFERENÇA (ZERO-SHOT)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "diferenca_casos = []\n",
    "for rp, ri in zip(resultados_padrao, resultados_isr):\n",
    "    if rp[\"obtido\"] != ri[\"obtido\"]:\n",
    "        diferenca_casos.append({\n",
    "            \"cliente_id\": rp[\"cliente_id\"],\n",
    "            \"esperado\": rp[\"esperado\"],\n",
    "            \"padrao\": rp[\"obtido\"],\n",
    "            \"isr\": ri[\"obtido\"],\n",
    "            \"padrao_acertou\": rp[\"acertou\"],\n",
    "            \"isr_acertou\": ri[\"acertou\"],\n",
    "            \"isr_valor\": ri.get(\"isr_valor\", 0),\n",
    "            \"eh_ficticio\": rp[\"eh_ficticio\"]\n",
    "        })\n",
    "\n",
    "if diferenca_casos:\n",
    "    for caso in diferenca_casos:\n",
    "        print(f\"\\nCliente: {caso['cliente_id']}\")\n",
    "        print(f\"  Esperado: {caso['esperado']}\")\n",
    "        print(f\"  Padrão:   {caso['padrao']} ({'CORRETO' if caso['padrao_acertou'] else 'ERRADO'})\")\n",
    "        print(f\"  ISR:      {caso['isr']} ({'CORRETO' if caso['isr_acertou'] else 'ERRADO'})\")\n",
    "        print(f\"  ISR Valor: {caso['isr_valor']:.4f}\")\n",
    "        if caso['eh_ficticio']:\n",
    "            if caso['isr_acertou'] and not caso['padrao_acertou']:\n",
    "                print(f\"  [ISR PROTEGEU] Cliente fictício bloqueado!\")\n",
    "else:\n",
    "    print(\"\\nNenhuma diferença entre os modelos nos casos testados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Salvando Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar resultados em JSON\n",
    "output_dir = PROJECT_ROOT / \"outputs\" / \"notebook_results\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_file = output_dir / f\"comparacao_zero_shot_{timestamp}.json\"\n",
    "\n",
    "# Preparar dados para salvar (remover objetos não serializáveis)\n",
    "def limpar_para_json(resultados):\n",
    "    limpos = []\n",
    "    for r in resultados:\n",
    "        limpo = {}\n",
    "        for k, v in r.items():\n",
    "            if k == \"resposta_completa\":\n",
    "                continue\n",
    "            # Converter tipos numpy e bool para tipos Python nativos\n",
    "            if hasattr(v, 'item'):  # numpy types\n",
    "                limpo[k] = v.item()\n",
    "            elif isinstance(v, bool):\n",
    "                limpo[k] = bool(v)\n",
    "            elif isinstance(v, dict):\n",
    "                limpo[k] = {kk: (vv.item() if hasattr(vv, 'item') else bool(vv) if isinstance(vv, bool) else vv) for kk, vv in v.items()}\n",
    "            else:\n",
    "                limpo[k] = v\n",
    "        limpos.append(limpo)\n",
    "    return limpos\n",
    "\n",
    "dados_salvar = {\n",
    "    \"metadata\": {\n",
    "        \"timestamp\": timestamp,\n",
    "        \"modelo\": MODEL_NAME,\n",
    "        \"versao\": \"3.0-zero-shot\",\n",
    "        \"total_casos\": len(casos_teste),\n",
    "        \"descricao\": \"Avaliação Zero-Shot: modelo recebe apenas políticas do banco, sem instruções detalhadas\"\n",
    "    },\n",
    "    \"resultados_padrao\": limpar_para_json(resultados_padrao),\n",
    "    \"resultados_isr\": limpar_para_json(resultados_isr),\n",
    "    \"metricas_padrao\": metricas_padrao,\n",
    "    \"metricas_isr\": metricas_isr\n",
    "}\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(dados_salvar, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"[OK] Resultados salvos em: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Conclusões (Zero-Shot)\n",
    "\n",
    "### Principais Descobertas - Modo Zero-Shot\n",
    "\n",
    "| Aspecto | Modelo Padrão | Agente ISR |\n",
    "|---------|---------------|------------|\n",
    "| **Contexto** | Apenas políticas | Apenas políticas + ISR |\n",
    "| **Instruções** | NENHUMA (zero-shot) | NENHUMA (zero-shot) |\n",
    "| **Detecção de Alucinação** | Depende da interpretação | Hard Veto integrado |\n",
    "| **Consistência** | Variável | Verificada via permutações |\n",
    "\n",
    "### Diferenças em relação à versão com instruções (v2)\n",
    "\n",
    "1. **Sem prompt guiado**: O modelo precisa inferir como processar a análise\n",
    "2. **Teste de robustez**: Avalia capacidade de seguir regras complexas sem exemplos\n",
    "3. **Baseline real**: Mostra desempenho do modelo sem \"ajuda\"\n",
    "\n",
    "### Recomendações\n",
    "\n",
    "1. **Compare com v2**: Verifique se as instruções detalhadas melhoram o desempenho\n",
    "2. **ISR continua útil**: Mesmo em zero-shot, ISR detecta instabilidades\n",
    "3. **Políticas bem escritas são essenciais**: Em zero-shot, a qualidade das políticas é crítica"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
